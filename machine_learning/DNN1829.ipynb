{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN1829.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x85oa8X9Xzqj"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_excel('f_029df.xlsx')\n",
        "df2 = pd.read_excel('f_9218df.xlsx')\n",
        "df3 = pd.read_excel('f_18224df.xlsx')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Nhd-R_lpgvmt",
        "outputId": "438c7c5c-676a-425f-f4c3-1c6765070422"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>dong</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>ffc</th>\n",
              "      <th>nfnc</th>\n",
              "      <th>nfc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>nsnc</th>\n",
              "      <th>nsc</th>\n",
              "      <th>총생활인구수</th>\n",
              "      <th>affnc</th>\n",
              "      <th>affc</th>\n",
              "      <th>anfnc</th>\n",
              "      <th>anfc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>ansnc</th>\n",
              "      <th>ansc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>가락1동</td>\n",
              "      <td>127.108235</td>\n",
              "      <td>37.495329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.164634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.322362</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.022764</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.034783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>가락2동</td>\n",
              "      <td>127.130643</td>\n",
              "      <td>37.495860</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.320622</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.056098</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>가락본동</td>\n",
              "      <td>127.121640</td>\n",
              "      <td>37.497217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.154472</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.445918</td>\n",
              "      <td>0.045161</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.040650</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.078261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>가리봉동</td>\n",
              "      <td>126.888257</td>\n",
              "      <td>37.482555</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108998</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.293902</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.234783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>가산동</td>\n",
              "      <td>126.884341</td>\n",
              "      <td>37.476835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.562965</td>\n",
              "      <td>0.335484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.343902</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.286957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  dong  ...      afsc  ansnc      ansc\n",
              "0           0             0  가락1동  ...  0.022764  0.012  0.034783\n",
              "1           1             1  가락2동  ...  0.043902  0.064  0.130435\n",
              "2           2             2  가락본동  ...  0.040650  0.064  0.078261\n",
              "3           3             3  가리봉동  ...  0.034146  0.392  0.234783\n",
              "4           4             4   가산동  ...  0.058537  0.408  0.286957\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z50DrnmGgvu_"
      },
      "source": [
        "# 필요없는 column 삭제\n",
        "df1 = df1.drop('Unnamed: 0', axis = 1)\n",
        "df1 = df1.drop('Unnamed: 0.1', axis = 1)\n",
        "df1 = df1.drop('X', axis = 1)\n",
        "df1 = df1.drop('Y', axis = 1)\n",
        "\n",
        "df2 = df2.drop('Unnamed: 0', axis = 1)\n",
        "df2 = df2.drop('Unnamed: 0.1', axis = 1)\n",
        "df2 = df2.drop('X', axis = 1)\n",
        "df2 = df2.drop('Y', axis = 1)\n",
        "\n",
        "df3 = df3.drop('Unnamed: 0', axis = 1)\n",
        "df3 = df3.drop('Unnamed: 0.1', axis = 1)\n",
        "df3 = df3.drop('X', axis = 1)\n",
        "df3 = df3.drop('Y', axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7c8gcxXi8ac"
      },
      "source": [
        "# 0 to 9시 데이터와 18시 to 24시 데이터의 총생활인구수를 평균내준 값을 기존의 총생활인구 column과 교체해줍니다.\n",
        "# populaton column이 마지막에 오면 보기 수월합니다.\n",
        "df1['population'] = (df1['총생활인구수'] + df3['총생활인구수'])/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrHI-Cr6mRfV"
      },
      "source": [
        "\n",
        "df1 = df1.drop('총생활인구수', axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "2MF23WqdmV2p",
        "outputId": "01470f6c-74be-457c-98e2-56b628564104"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>ffc</th>\n",
              "      <th>nfnc</th>\n",
              "      <th>nfc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>nsnc</th>\n",
              "      <th>nsc</th>\n",
              "      <th>affnc</th>\n",
              "      <th>affc</th>\n",
              "      <th>anfnc</th>\n",
              "      <th>anfc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>ansnc</th>\n",
              "      <th>ansc</th>\n",
              "      <th>population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>가락1동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.164634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.022764</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.034783</td>\n",
              "      <td>0.299870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>가락2동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.056098</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.303859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>가락본동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.154472</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.045161</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.040650</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.078261</td>\n",
              "      <td>0.426756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>가리봉동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.293902</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.234783</td>\n",
              "      <td>0.105551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>가산동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.335484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.343902</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.549815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dong  highway      ffnc       ffc  ...      afsc  ansnc      ansc  population\n",
              "0  가락1동      0.0  0.225806  0.000000  ...  0.022764  0.012  0.034783    0.299870\n",
              "1  가락2동      0.0  0.161290  0.166667  ...  0.043902  0.064  0.130435    0.303859\n",
              "2  가락본동      0.0  0.032258  0.000000  ...  0.040650  0.064  0.078261    0.426756\n",
              "3  가리봉동      0.0  0.032258  0.000000  ...  0.034146  0.392  0.234783    0.105551\n",
              "4   가산동      0.0  1.000000  0.000000  ...  0.058537  0.408  0.286957    0.549815\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_hUaB84q5fI"
      },
      "source": [
        "# 전에 heatmap을 그린것을 보면 ffc는 데이터가 너무 없어서 -값 내지는 매우 작은값을 보였습니다.\n",
        "# 머신러닝돌릴때는 ffc와 affc도 drop합시다.\n",
        "df1 = df1.drop('ffc', axis = 1)\n",
        "df1 = df1.drop('affc', axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcS-86vCCL8y"
      },
      "source": [
        "df1 = df1.drop(columns=['nfnc','nfc','nsnc','nsc','anfnc','anfc','ansnc','ansc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmY7fPN0scg-"
      },
      "source": [
        "# null값을 0으로 채워둡니다.\n",
        "df1 = df1.fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlIz9cBci8ae"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "u5QtwbPMktjS",
        "outputId": "26b17245-17e6-4ec9-e0ed-796b4d3c8e38"
      },
      "source": [
        "# 데이터들의 histgram을 봅시다.\n",
        "import matplotlib.pyplot as plt\n",
        "df1.hist(bins = 50, figsize = (20,15))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 9 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8dnBadNeVmcs",
        "outputId": "1e95e1e3-595a-4016-bfdc-17061a189ab9"
      },
      "source": [
        "# population 데이터가 class값으로 들어가게 될것입니다.\n",
        "# 우리는 population data를 치우치지 않게 여러 set 뽑아주는 StratifiedKFold를 하고 싶습니다.\n",
        "# population을 5개의 구역으로 나눠줬습니다. kfold를 할때 각 구역에서 일정한 값들이 뽑히게 할것입니다.\n",
        "\n",
        "# pd.cut을 이용하여 population을 5개의 구역으로 나눈것을 pop_cut이라는 column에 담았습니다,\n",
        "df1[\"pop_cat\"] = pd.cut(df1[\"population\"],\n",
        "                              bins = [0.0, 0.1, 0.2, 0.3, 0.4, 1.0],\n",
        "                              labels = [1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "df1[\"pop_cat\"].hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f368eb2bfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlU83M8ywoYe",
        "outputId": "b76bb247-c078-429d-96b4-fcb0678c1d00"
      },
      "source": [
        "# average, standard deviation\n",
        "import numpy as np\n",
        "a = [1,3,5,7,9]\n",
        "b = sum(a)/5\n",
        "c = b*np.ones(5)\n",
        "d = np.sqrt(sum((a - c)**2)/5)\n",
        "print(b)\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n",
            "2.8284271247461903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q3OqwzhW1uq",
        "outputId": "9bfd65df-ed03-4316-a3b2-5c7a85bdee44"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# seed를 정해줍니다.\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "data = df1.values\n",
        "x = data[:,1:-2].astype(float)  # feature\n",
        "y = data[:,-2].astype(float)   # population\n",
        "y_cat = data[:,-1].astype(float) # pop_cut\n",
        "\n",
        "#  StratifiedKFold\n",
        "n_fold = 5\n",
        "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)\n",
        "  \n",
        "# 에러를 담기위해 먼저 빈 array를 만들었습니다.  \n",
        "test_error_set = []  \n",
        "train_error_set = [] \n",
        "\n",
        "# valiation loss가 patience만큼 반복해도 변하지 않거나 나빠지면 학습을 중단하게 설정합니다.  \n",
        "# patience 조정가능!\n",
        "ESC = EarlyStopping(monitor = 'val_loss', patience = 10) \n",
        "\n",
        "for train, test in skf.split(x,y_cat): # StratifiedKFold로 나눈 데이터 셋을 받습니다. n_fold가 5이므로 for문은 5번 돌것입니다.\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7,input_dim = 7, activation= 'relu'))\n",
        "  model.add(Dense(1,activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss = 'mean_squared_error', optimizer = 'adam') \n",
        "  model.fit(x[train],y[train], validation_split= 0.2, epochs = 300, batch_size= 10, callbacks = [ESC])\n",
        "  # fold별로 error를 받아줘서 위에 만든 빈 array에 담아줍니다.\n",
        "  train_error = mean_squared_error(y[train], model.predict(x[train])) \n",
        "  test_error = mean_squared_error(y[test], model.predict(x[test]))\n",
        "  train_error_set.append(train_error)\n",
        "  test_error_set.append(test_error)\n",
        "# error들의 평균과 표준편차를 구해줍니다.\n",
        "average_train_error = sum(train_error_set)/5\n",
        "ate1 = average_train_error*np.ones(5)\n",
        "train_standard_deviation = np.sqrt(sum((train_error_set - ate1)**2)/5)\n",
        "average_test_error = sum(test_error_set)/5\n",
        "ate2 = average_test_error*np.ones(5)\n",
        "test_standard_deviation = np.sqrt(sum((test_error_set - ate2)**2)/5)\n",
        "\n",
        "print('train:',average_train_error,train_standard_deviation)\n",
        "print('test:',average_test_error,test_standard_deviation)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0746 - val_loss: 0.0595\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0493\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0415\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0351\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0301\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0307 - val_loss: 0.0267\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0239\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0218\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0224 - val_loss: 0.0204\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - val_loss: 0.0195\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0199 - val_loss: 0.0189\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0185\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - val_loss: 0.0183\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0181\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0181\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0180\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0180\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0180\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0179 - val_loss: 0.0180\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0719 - val_loss: 0.0538\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0441\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0365\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0305\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0353 - val_loss: 0.0258\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0226\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0202\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0186\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0175\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0204 - val_loss: 0.0168\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0163\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - val_loss: 0.0161\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0160\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0160\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0161\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0162\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0162\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0163\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0163\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0164\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0165\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0164\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0164\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0751 - val_loss: 0.0544\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0594 - val_loss: 0.0442\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0369\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0312\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0267\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0234\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0256 - val_loss: 0.0210\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0195\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0184\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0177\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0181 - val_loss: 0.0173\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0171\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0170\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0171\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0171\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0172\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0173\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0174\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0175\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0175\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0175\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0175\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0158 - val_loss: 0.0176\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0344 - val_loss: 0.0279\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0246\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0219\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0245 - val_loss: 0.0206\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0188\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0218 - val_loss: 0.0178\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0171\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - val_loss: 0.0164\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0159\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0153\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0149\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0146\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0170 - val_loss: 0.0143\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0140\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0138\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0135\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0133\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0132\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0130\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0129\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0148 - val_loss: 0.0128\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0128\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0127\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0126\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0126\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0126\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0125\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0125\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0125\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0124\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0124\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0125\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0138 - val_loss: 0.0125\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0125\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0136 - val_loss: 0.0125\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0125\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0125\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0142 - val_loss: 0.0127\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0125\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0125\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0125\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0671 - val_loss: 0.0603\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0502\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0417\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0352\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0300\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0262\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0233\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0212\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0197\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0186\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0179\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0175\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0172\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0170\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0169\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0168\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "train: 0.015978522350726238 0.001567767625561979\n",
            "test: 0.01650003576306697 0.00361061748955917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLhNvGGYVme8"
      },
      "source": [
        "# 위에서 만든 모델을 바탕으로 layer 수와 node 갯수를 변수로 받는 함수를 만들어줍니다.\n",
        "\n",
        "def construct_layer(layer_num,node_num):\n",
        "  test_error_set = []  \n",
        "  train_error_set = []  \n",
        "  \n",
        "  for train, test in skf.split(x,y_cat):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(node_num,input_dim = 7, activation= 'relu'))\n",
        "    model.add(Dense(layer_num,activation = 'relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss = 'mean_squared_error', optimizer = 'adam') \n",
        "    model.fit(x[train],y[train], validation_split= 0.2, epochs = 300, batch_size= 10, callbacks = [ESC])\n",
        "    train_error = mean_squared_error(y[train], model.predict(x[train]))\n",
        "    test_error = mean_squared_error(y[test], model.predict(x[test]))\n",
        "    train_error_set.append(train_error)\n",
        "    test_error_set.append(test_error)\n",
        "  \n",
        "  average_train_error = sum(train_error_set)/5\n",
        "  ate1 = average_train_error*np.ones(5)\n",
        "  train_standard_deviation = np.sqrt(sum((train_error_set - ate1)**2)/5)\n",
        "  average_test_error = sum(test_error_set)/5\n",
        "  ate2 = average_test_error*np.ones(5)\n",
        "  test_standard_deviation = np.sqrt(sum((test_error_set - ate2)**2)/5)\n",
        "\n",
        "  return [average_train_error, train_standard_deviation,average_test_error,test_standard_deviation]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2DT3zJ51v-d",
        "outputId": "1eaee509-7805-4309-da58-f5916f5216c8"
      },
      "source": [
        "a = construct_layer(1,15)\n",
        "print(a)\n",
        "#결과가 list로 잘 출력이 되네요!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0714 - val_loss: 0.0597\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0587 - val_loss: 0.0494\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0415\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0351\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0300\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0266\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0238\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0217\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0204\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0195\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0199 - val_loss: 0.0189\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0185\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0183\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0181\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0181\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0181 - val_loss: 0.0180\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0180\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0180\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0180\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0182\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0182\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0181\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0182\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0182\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0182\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0706 - val_loss: 0.0531\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0438\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0363\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0304\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0258\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0226\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0202\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0186\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0175\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0203 - val_loss: 0.0167\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0163\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0161\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - val_loss: 0.0160\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0160\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0161\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0162\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0162\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0163\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0163\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0164\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0165\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0164\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0164\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0166\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0167\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0167\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0167\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0168\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0168\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0167\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0171 - val_loss: 0.0166\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0165\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0166\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0820 - val_loss: 0.0558\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0602 - val_loss: 0.0449\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0371\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0315\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0347 - val_loss: 0.0269\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0236\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0212\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0196\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0209 - val_loss: 0.0185\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0178\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0173\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0171\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0170\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0170\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0162 - val_loss: 0.0171\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0172\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0173\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0174\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0175\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0175\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0175\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0175\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0176\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0176\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0177\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0178\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0177\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0179\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0178\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0178\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0177\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0176\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0176\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0417 - val_loss: 0.0228\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0149\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0144\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0142\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0136\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0135\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0133\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0131\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0130\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0129\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0128\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0128\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0128\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0128\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0128\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0127\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0127\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0129\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0128\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0128\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0128\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0129\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0129\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0130\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0129\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0130\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0123 - val_loss: 0.0131\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0131\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0131\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0134\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0134\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0670 - val_loss: 0.0603\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0555 - val_loss: 0.0501\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0460 - val_loss: 0.0417\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0352\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0300\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0262\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0242 - val_loss: 0.0233\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0216 - val_loss: 0.0212\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0197\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - val_loss: 0.0186\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0179\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0167 - val_loss: 0.0175\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0172\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0160 - val_loss: 0.0170\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0169\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0168\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0168\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0168\n",
            "[0.015816240831043597, 0.0018807361985741628, 0.016576050161301203, 0.0034971041138037993]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJtsW1GqVmhR",
        "outputId": "2a1b819b-bc0f-48f8-f38e-c75d5b09183d"
      },
      "source": [
        "x_arr = [] # train error\n",
        "y_arr = [] # test error\n",
        "# hidden layer의 node수를 7로 해두고 층을 계속 쌓았을때 loss가 어떻게 변하는지 그려봅시다.\n",
        "max_layer = 20\n",
        "for i in range(0,max_layer):\n",
        "  a = construct_layer(i,7)\n",
        "  x_arr.append(a[0])\n",
        "  y_arr.append(a[2])\n",
        "  print('layer:',i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0129\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0128\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0128\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0128\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0128\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0129\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0129\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0129\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0129\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0130\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0131\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0217 - val_loss: 0.0173\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0161\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0156\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0153\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0149\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0148\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0145\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0141\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0141\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0141\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0140\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0140\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0140\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0140\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0140\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0140\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0140\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0140\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0140\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0141\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0140\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0140\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0140\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0140\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0140\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0140\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0140\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0140\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0140\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0141\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0141\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0142\n",
            "layer: 6\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0785 - val_loss: 0.0553\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0529 - val_loss: 0.0401\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0386 - val_loss: 0.0300\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0232\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0193\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0179\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0173\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0172\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0171\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0170\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0170\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0168\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0167\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0166\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0165\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0165\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0163\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0163\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0161\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0161\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0159\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0158\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0157\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0156\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0154\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0153\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0153\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0151\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0150\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0150\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0147\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0146\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0146\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0145\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0145\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0145\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0144\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0145\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0144\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0144\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0143\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0143\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0143\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0143\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0143\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0142\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0142\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0142\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0141\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0142\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0141\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0140\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0141\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0140\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0140\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0140\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0140\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0140\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0139\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0140\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0140\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0139\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0139\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0139\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0140\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0140\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0140\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0139\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0140\n",
            "Epoch 70/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0141\n",
            "Epoch 71/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0141\n",
            "Epoch 72/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0140\n",
            "Epoch 73/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0139\n",
            "Epoch 74/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0141\n",
            "Epoch 75/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0140\n",
            "Epoch 76/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0139\n",
            "Epoch 77/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0140\n",
            "Epoch 78/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0140\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0282 - val_loss: 0.0137\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0130\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0117\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0116\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0112\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0111\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0109\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0111\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0114\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0110\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0113\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0112\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0112\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0111\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0108\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0112\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0110\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0112\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0108\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0109\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0110\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0109\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0111\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0111\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0115\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0109\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0112\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0113\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0109\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0859 - val_loss: 0.0522\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0490 - val_loss: 0.0296\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0272 - val_loss: 0.0200\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0192\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0185\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0174\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0169\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0161\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0156\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0150\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0142\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0144\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0141\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0140\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0141\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0140\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0138\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0139\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0136\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0136\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0140\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0138\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0135\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0137\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0135\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0135\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0136\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0138\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0134\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0137\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0135\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0138\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0136\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0134\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0137\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0137\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0137\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0136\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0136\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.1196 - val_loss: 0.0967\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0663 - val_loss: 0.0602\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0397\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0316\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0277\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0256\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0244\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0230\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0217\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0204\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0195\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0188\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0182\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0175\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0169\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0166\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0164\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0161\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0160\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0157\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0154\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0153\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0152\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0151\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0150\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0150\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0149\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0146\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0144\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0144\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0143\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0144\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0145\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0144\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0145\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0146\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0145\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0145\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0147\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0633 - val_loss: 0.0393\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0206\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0148\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0142\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0143\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0143\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0144\n",
            "layer: 7\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.1346 - val_loss: 0.0640\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0715 - val_loss: 0.0400\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0409 - val_loss: 0.0230\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0173\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0190 - val_loss: 0.0173\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0168\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0168\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0165\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0162\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0160\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0159\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0157\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0142 - val_loss: 0.0156\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0156\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0155\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0154\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0153\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0152\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0152\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0152\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0151\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0150\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0149\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0149\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0149\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0149\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0149\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0149\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0149\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0149\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0149\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0147\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0147\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0147\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0146\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0147\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0147\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0147\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0146\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0147\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0146\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0146\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0147\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0146\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0144\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0145\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0145\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0145\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0145\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 70/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 71/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 72/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 73/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0145\n",
            "Epoch 74/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0144\n",
            "Epoch 75/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0144\n",
            "Epoch 76/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0144\n",
            "Epoch 77/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 78/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 79/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0144\n",
            "Epoch 80/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 81/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 82/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0144\n",
            "Epoch 83/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0143\n",
            "Epoch 84/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0145\n",
            "Epoch 85/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 86/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 87/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 88/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0144\n",
            "Epoch 89/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0144\n",
            "Epoch 90/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0144\n",
            "Epoch 91/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0144\n",
            "Epoch 92/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0144\n",
            "Epoch 93/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0144\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0516 - val_loss: 0.0281\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0292 - val_loss: 0.0252\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0257 - val_loss: 0.0218\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0199\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0172\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0158\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0147\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0139\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0133\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0130\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0127\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0121\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0124\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0124\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0123\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0121\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0118\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0122\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0120\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0123\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0117\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0118\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0120\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0120\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0120\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0122\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0125\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0119\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0125\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0123\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0119\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0480 - val_loss: 0.0268\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0151\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0148\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0149\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0150\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0149\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0149\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0148\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0148\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0147\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0145\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0147\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0145\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0145\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0145\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0144\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0143\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0143\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0142\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0141\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0142\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0142\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0142\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0139\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0140\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0139\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0138\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0140\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0138\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0143\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0139\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0138\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0139\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0137\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0142\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0135\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0139\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0139\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0139\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0139\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0138\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0142\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0137\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0145\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0138\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0138\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0312 - val_loss: 0.0193\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0148\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0145\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0140\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0138\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0137\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0136\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0134\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0133\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0132\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0131\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0131\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0130\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0130\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0128\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0128\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0127\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0126\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0126\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0126\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0126\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0126\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0126\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0126\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0127\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0127\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0127\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0127\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0127\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0127\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0127\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 23ms/step - loss: 0.0726 - val_loss: 0.0423\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0373 - val_loss: 0.0218\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0228 - val_loss: 0.0172\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0167\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0161\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0158\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0155\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0154\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0152\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0151\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0151\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0150\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0149\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0149\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0148\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0148\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0148\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0147\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0147\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0147\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0147\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0146\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0146\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0146\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0146\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0146\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0146\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0146\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0146\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0146\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0146\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0146\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0146\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0146\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0146\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0146\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0146\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0146\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0146\n",
            "layer: 8\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0602 - val_loss: 0.0439\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0329 - val_loss: 0.0250\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0198\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0190 - val_loss: 0.0186\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0180\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0176\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0170\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0165\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0162\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0158\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0155\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0153\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0148\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0144\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0140\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0137\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0132\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0131\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0129\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0128\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0127\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0128\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0127\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0128\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0126\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0127\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0127\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0128\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0127\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0129\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0128\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0128\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0129\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0128\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0415 - val_loss: 0.0197\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0136\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0132\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0129\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0125\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0121\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0120\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0118\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0117\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0116\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0116\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0112\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0113\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0112\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0111\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0110\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0108\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0111\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0108\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0110\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0108\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0108\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0107\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0108\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0108\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0108\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0111\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0106\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0111\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0109\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0107\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0109\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0109\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0112\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0112\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0110\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0110\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0107\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0597 - val_loss: 0.0318\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0259 - val_loss: 0.0180\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0172\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0171\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0167\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0164\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0161\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0158\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0155\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0152\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0150\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0147\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0149\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0146\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0146\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0148\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0145\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0145\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0144\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0143\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0143\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0144\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0143\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0143\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0143\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0145\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0144\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0143\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0143\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0143\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0143\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0144\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0144\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0146\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0146\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0144\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0144\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0143\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0146\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0144\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0144\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0666 - val_loss: 0.0494\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0380 - val_loss: 0.0266\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0208 - val_loss: 0.0171\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0160\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0155\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0151\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0147\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0144\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0141\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0139\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0137\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0136\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0134\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0132\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0131\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0130\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0129\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0128\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0127\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0126\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0126\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0128\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0127\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0127\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0127\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0127\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0128\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0128\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0599 - val_loss: 0.0319\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0241 - val_loss: 0.0185\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0181\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0175\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0168\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0161\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0157\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0156\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0155\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0154\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0154\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0153\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0153\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0152\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0152\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0152\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0153\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0152\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0151\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0151\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0151\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0151\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0151\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0151\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0151\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0150\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0150\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0150\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0150\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0149\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0150\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0149\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0149\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0150\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0148\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0148\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0148\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0148\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0148\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0148\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0148\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0148\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0148\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0149\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0148\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0148\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0148\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0148\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0147\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0147\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0149\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0148\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0147\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0147\n",
            "layer: 9\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0597 - val_loss: 0.0313\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0286 - val_loss: 0.0201\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0193\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0208 - val_loss: 0.0180\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0198 - val_loss: 0.0168\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0161\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0158\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0154\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0153\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0153\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0153\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0154\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0153\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0152\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0151\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0151\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0149\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0148\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0148\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0147\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0146\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0147\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0145\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0146\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0146\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0145\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0144\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0143\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0142\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0143\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0144\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0142\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0142\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0142\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0143\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0145\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0143\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0143\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0144\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0143\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0144\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0143\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0144\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0145\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0583 - val_loss: 0.0265\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0128\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0135\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0134\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0132\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0129\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0128\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0128\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0129\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0128\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0130\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0124\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0127\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0126\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0126\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0124\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0122\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0124\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0125\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0123\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0118\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0122\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0122\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0119\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0120\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0122\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0126\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0119\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0128\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0124\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0119\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0226 - val_loss: 0.0144\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0154\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0142\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0141\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0143\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0141\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0141\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0139\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0137\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0136\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0139\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0135\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0136\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0141\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0135\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0139\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0135\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0138\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0136\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0137\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0137\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0136\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0655 - val_loss: 0.0322\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0301 - val_loss: 0.0156\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0205 - val_loss: 0.0142\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0139\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0136\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0135\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0134\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0132\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0131\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0131\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0130\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0130\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0129\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0128\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0127\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0127\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0127\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0127\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0127\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0127\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0127\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0127\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0127\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0127\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0127\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0128\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0127\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0127\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0496 - val_loss: 0.0319\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0167\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0157\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0155\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0152\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0150\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0150\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0149\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0147\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0146\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0147\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0145\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0144\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0143\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0143\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0143\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0143\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0143\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0144\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0144\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0143\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0143\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0143\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0143\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0143\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0142\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0143\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0142\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0142\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0142\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0143\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0143\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0143\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0143\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0143\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0143\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0143\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0143\n",
            "layer: 10\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0417 - val_loss: 0.0219\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0174 - val_loss: 0.0142\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0140\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0139\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0138\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0138\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0137\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0136\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0136\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0136\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0135\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0137\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0135\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0135\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0134\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0135\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0135\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0134\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0134\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0134\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0134\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0133\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0133\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0133\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0133\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0132\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0132\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0133\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0132\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0133\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0132\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0132\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0132\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0132\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0130\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0130\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0130\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0131\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0131\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0131\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0130\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0130\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0130\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0130\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0130\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0130\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0129\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0129\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0129\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0130\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0129\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0130\n",
            "Epoch 70/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0130\n",
            "Epoch 71/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0130\n",
            "Epoch 72/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0129\n",
            "Epoch 73/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0130\n",
            "Epoch 74/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0130\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0856 - val_loss: 0.0526\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0532 - val_loss: 0.0319\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0321 - val_loss: 0.0205\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0209 - val_loss: 0.0174\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0172\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0172 - val_loss: 0.0167\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0163\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0159\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0157\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0155\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0156\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0149\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0147\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0147\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0145\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0143\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0138\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0138\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0134\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0134\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0131\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0127\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0127\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0126\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0124\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0123\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0124\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0122\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0119\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0122\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0118\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0119\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0119\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0121\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0122\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0119\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0120\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0116\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0117\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0116\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0117\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0116\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0116\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0117\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0117\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0116\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0120\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0116\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0118\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0116\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0114\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0116\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0114\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0116\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0116\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0117\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0120\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0118\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0117\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0116\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0118\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0226 - val_loss: 0.0141\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0135\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0130\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0131\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0129\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0131\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0135\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0132\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0134\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0131\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0135\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0135\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0134\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0134\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0463 - val_loss: 0.0262\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0139\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0135\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0163 - val_loss: 0.0133\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0132\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0130\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0128\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0128\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0127\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0127\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0128\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0127\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0127\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0128\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0128\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0128\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0128\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0129\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0129\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0130\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0711 - val_loss: 0.0397\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0180\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0151\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0150\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0147\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0147\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0147\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0147\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0147\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0147\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0147\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0148\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0148\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0148\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0148\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0149\n",
            "layer: 11\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0650 - val_loss: 0.0426\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0359 - val_loss: 0.0218\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0172\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0169\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0163\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0159\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0167 - val_loss: 0.0156\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0152\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0150\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0148\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0146\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0147\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0143\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0141\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0140\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0140\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0139\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0138\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0138\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0137\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0137\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0137\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0137\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0136\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0135\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0135\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0135\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0135\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0135\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0136\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0134\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0135\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0134\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0134\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0134\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0135\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0134\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0133\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0134\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0133\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0133\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0133\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0133\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0134\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0133\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0133\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0134\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0134\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0659 - val_loss: 0.0346\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0317 - val_loss: 0.0181\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0191 - val_loss: 0.0159\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0156\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0148\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0142\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0138\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0133\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0130\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0127\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0126\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0121\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0121\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0121\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0119\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0119\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0116\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0119\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0118\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0119\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0115\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0116\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0117\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0114\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0115\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0116\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0120\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0114\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0121\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0118\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0115\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0117\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0120\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0121\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0344 - val_loss: 0.0202\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0188 - val_loss: 0.0160\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0148\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0142\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0140\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0138\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0137\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0134\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0134\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0122 - val_loss: 0.0131\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0133\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0131\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0134\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0131\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0131\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0134\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0131\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0131\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0132\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0130\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0131\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0132\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0132\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0130\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0132\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0134\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0133\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0132\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0131\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0131\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0129\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0130\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0131\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0134\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0133\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0130\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0132\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0131\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0134\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0130\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0131\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0528 - val_loss: 0.0298\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0217 - val_loss: 0.0156\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0148\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0143\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0138\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0135\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0132\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0127\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0127\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0127\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0127\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0125\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0125\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0124\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0124\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0124\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0124\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0124\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0124\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0123\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0125\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0123\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0123\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0123\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0123\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0124\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0123\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0125\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0125\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0124\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0124\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0581 - val_loss: 0.0428\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0298 - val_loss: 0.0222\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0158\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0155\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0154\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0153\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0153\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0152\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0151\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0150\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0151\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0150\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0150\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0149\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0149\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0148\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0149\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0148\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0149\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0148\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0148\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0147\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0148\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0148\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0149\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0149\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0150\n",
            "layer: 12\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0537 - val_loss: 0.0300\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0230 - val_loss: 0.0143\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0133\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0134\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0132\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0131\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0132\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0131\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0131\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0131\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0131\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0131\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0131\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0130\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0131\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0130\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0130\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0131\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0131\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0131\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0131\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0131\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0131\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0132\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0131\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0131\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0536 - val_loss: 0.0282\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0248 - val_loss: 0.0136\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0131\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0129\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0125\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0121\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0120\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0118\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0117\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0116\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0116\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0112\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0113\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0113\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0112\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0112\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0109\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0112\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0110\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0111\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0108\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0108\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0109\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0108\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0108\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0109\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0113\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0108\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0110\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0111\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0108\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0110\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0112\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0114\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0115\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0111\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0113\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0109\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0110\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0109\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0110\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0387 - val_loss: 0.0205\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0135\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0135\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0135\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0136\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0135\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0135\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0135\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0134\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0134\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0134\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0136\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0134\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0134\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0138\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0134\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0136\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0134\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0136\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0541 - val_loss: 0.0239\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0138\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0136\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0136\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0136\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0136\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0135\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0135\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0134\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0134\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0134\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0134\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0133\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0133\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0133\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0132\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0133\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0133\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0133\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0133\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0133\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0133\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0133\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0133\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0133\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0133\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.1017 - val_loss: 0.0635\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0485 - val_loss: 0.0316\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0276 - val_loss: 0.0259\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0238\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0211 - val_loss: 0.0220\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0195 - val_loss: 0.0209\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0199\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0189\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0183\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0178\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0173\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0168\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0165\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0163\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0160\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0158\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0156\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0155\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0154\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0153\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0152\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0152\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0152\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0151\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0152\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0151\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0151\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0151\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0151\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0151\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0150\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0150\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0150\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0151\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0151\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0151\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0150\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0151\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0150\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0150\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0149\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0150\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0150\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0150\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0149\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0149\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0149\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0149\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0149\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0149\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0148\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0149\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0150\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0150\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0150\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0149\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0149\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 70/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 71/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0148\n",
            "Epoch 72/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0150\n",
            "Epoch 73/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0148\n",
            "Epoch 74/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0148\n",
            "Epoch 75/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0148\n",
            "Epoch 76/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0147\n",
            "Epoch 77/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0148\n",
            "Epoch 78/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 79/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0147\n",
            "Epoch 80/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0147\n",
            "Epoch 81/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0148\n",
            "Epoch 82/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0148\n",
            "Epoch 83/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0147\n",
            "Epoch 84/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0147\n",
            "Epoch 85/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0148\n",
            "Epoch 86/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0147\n",
            "Epoch 87/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0147\n",
            "Epoch 88/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0147\n",
            "Epoch 89/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0147\n",
            "Epoch 90/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0147\n",
            "Epoch 91/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0149\n",
            "Epoch 92/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0148\n",
            "Epoch 93/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0147\n",
            "Epoch 94/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0148\n",
            "Epoch 95/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0147\n",
            "Epoch 96/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0110 - val_loss: 0.0147\n",
            "Epoch 97/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0149\n",
            "Epoch 98/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0109 - val_loss: 0.0148\n",
            "layer: 13\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0571 - val_loss: 0.0279\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0218 - val_loss: 0.0139\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0140\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0138\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0136\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0135\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0135\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0133\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0133\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0132\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0132\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0131\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0132\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0131\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0132\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0132\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0132\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0132\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0133\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0132\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0132\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0132\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0498 - val_loss: 0.0248\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0231 - val_loss: 0.0165\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0183 - val_loss: 0.0169\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0163\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0157\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0150\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0146\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0147\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0140\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0145\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0135\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0132\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0133\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0134\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0128\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0125\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0125\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0128\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0137 - val_loss: 0.0127\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0128\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0117\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0121\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0121\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0122\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0119\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0122\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0128\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0118\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0137\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0125\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0120\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0322 - val_loss: 0.0165\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0133\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0129\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0130\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0133\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0132\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0133\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0133\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0133\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0132\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0131\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0116 - val_loss: 0.0133\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0438 - val_loss: 0.0288\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0225 - val_loss: 0.0194\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0184\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0175 - val_loss: 0.0178\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0171\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0165\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0159\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0152\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0147\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0141\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0138\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0134\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0132\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0130\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0129\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0128\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0128\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0128\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0128\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0128\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0129\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0131\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0130\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0131\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0132\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0132\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0134\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0447 - val_loss: 0.0275\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0178\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0172\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0168\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0165\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0162\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0161\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0159\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0158\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0155\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0156\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0154\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0153\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0152\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0151\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0151\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0152\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0150\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0149\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0149\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0150\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0150\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0151\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0151\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0150\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0150\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0150\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0150\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0151\n",
            "layer: 14\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0512 - val_loss: 0.0342\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0192 - val_loss: 0.0196\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0182\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0173\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0167\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0161\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0155\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0151\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0148\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0145\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0143\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0144\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0140\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0138\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0137\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0137\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0136\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0136\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0135\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0135\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0135\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0135\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0134\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0133\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0133\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0133\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0130 - val_loss: 0.0133\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0132\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0133\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0132\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0134\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0133\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0133\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0133\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0134\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0134\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0133\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0135\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0526 - val_loss: 0.0289\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0253 - val_loss: 0.0183\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0172\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0167\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0170 - val_loss: 0.0161\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0153\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0150\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0147\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0142\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0140\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0136\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0132\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0132\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0130\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0128\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0125\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0123\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0124\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0121\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0122\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0119\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0120\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0119\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0116\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0117\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0119\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0121\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0116\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0123\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0119\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0117\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0118\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0121\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0123\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0122\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0119\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0119\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0117\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0639 - val_loss: 0.0337\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0169\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0145\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0149\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0148\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0145\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0142\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0143\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0141\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0141\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0140\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0142\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0140\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0141\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0145\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0140\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0144\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0140\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0144\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0112 - val_loss: 0.0141\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0142\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0143\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0142\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0143\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0111 - val_loss: 0.0144\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0147\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0641 - val_loss: 0.0362\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0289 - val_loss: 0.0183\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0169\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0170 - val_loss: 0.0168\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0165\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0164\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0162\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0159\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0157\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0154\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0154\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0154\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0150\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0149\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0147\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0147\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0147\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0145\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0147\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0146\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0145\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0144\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0143\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0141\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0142\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0142\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0143\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0144\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0142\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0143\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0143\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0142\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0142\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0142\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0380 - val_loss: 0.0196\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0158\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0154\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0152\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0151\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0150\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0149\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0150\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0149\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0149\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0149\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0149\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0148\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0148\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0149\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0148\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0148\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0148\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0148\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0148\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0148\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0150\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0149\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0148\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0150\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0149\n",
            "layer: 15\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0510 - val_loss: 0.0261\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0194 - val_loss: 0.0166\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0164\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0162\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0159\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0156\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0155 - val_loss: 0.0154\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0151\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0148\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0145\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0143\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0142\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0140\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0139\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0139\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0139\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0137\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0136\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0137\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0136\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0135\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0139\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0135\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0136\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0136\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0135\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0134\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0133\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0132\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0134\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0138\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0138\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0136\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0135\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0134\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0135\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0135\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0334 - val_loss: 0.0141\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0125\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0119\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0120\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0118\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0117\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0116\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0116\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0114\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0114\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0112\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0111\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0112\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0112\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0111\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0110\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0109\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0111\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0110\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0110\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0108\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0108\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0109\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0108\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0108\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0109\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0112\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0107\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0111\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0109\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0107\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0109\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0111\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0112\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0113\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0111\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0109\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0108\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0561 - val_loss: 0.0318\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0287 - val_loss: 0.0160\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0132\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0135\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0135\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0134\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0132\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0134\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0130\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0132\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0129\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0133\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0130\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0130\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0133\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0130\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0131\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0132\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0131\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0131\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0131\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0325 - val_loss: 0.0177\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0145\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0142\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0138\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0135\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - val_loss: 0.0134\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0132\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0130\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0130\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0129\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0129\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0129\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0128\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0128\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0128\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0129\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0128\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0130\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0129\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0357 - val_loss: 0.0182\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0150\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0144\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0144\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0144\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0144\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0145\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0145\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0145\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0146\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0144\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0144\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0145\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0145\n",
            "layer: 16\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0565 - val_loss: 0.0293\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0215 - val_loss: 0.0145\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0141\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0138\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0136\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0134\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0136\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0134\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0135\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0135\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0136\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0136\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0139\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0141\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0143\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0143\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0143\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0144\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0588 - val_loss: 0.0294\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0256 - val_loss: 0.0167\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0164\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0157\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0158 - val_loss: 0.0147\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0139\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0149 - val_loss: 0.0136\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0134\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0132\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0144 - val_loss: 0.0130\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0128\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0140 - val_loss: 0.0125\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0125\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0125\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0123\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0121\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0119\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0121\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0119\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0119\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0115\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0116\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0115\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0113\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0113\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0114\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0117\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0111\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0119\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0113\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0110\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0113\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0113\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0117\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0115\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0113\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0113\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0111\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0109\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0111\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0109\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0113\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0113\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0112\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0108\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0114\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0111\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0112\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0116\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0110\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0108\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0114\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0107\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0110\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0109\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0123\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0111\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0115\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0112\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0110\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0114\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0107\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0116\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0110\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0114\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0107\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0116\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0111\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0112\n",
            "Epoch 70/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0113\n",
            "Epoch 71/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0114\n",
            "Epoch 72/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0115\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0496 - val_loss: 0.0221\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0142\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0142\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0137\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0137\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0139\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0138\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0137\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0137\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0133\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0120 - val_loss: 0.0133\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0137\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0133\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0134\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0138\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0133\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0135\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0133\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0134\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0135\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0135\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0373 - val_loss: 0.0194\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0152\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0148 - val_loss: 0.0147\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0141\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0138\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0137\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0138 - val_loss: 0.0135\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0133\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0132\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0133\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0135 - val_loss: 0.0132\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0133\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0131\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0131\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0132\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0132\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0132\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0131\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0134\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0132\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0130 - val_loss: 0.0131\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0130\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0131\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0132\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0131\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0132\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0134\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0132\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0133\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0132\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0132\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0134\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0328 - val_loss: 0.0175\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0156\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0155\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0154\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0153\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0153\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0153\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0153\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0151\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0151\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0152\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0151\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0151\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0151\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0152\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0152\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0124 - val_loss: 0.0153\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0153\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0152\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0153\n",
            "layer: 17\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0217 - val_loss: 0.0151\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0146\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0139\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0139\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0138\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0137\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0135\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0134\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0134\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0134\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0135\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0136\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0138\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0136\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0136\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0136\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0145\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0603 - val_loss: 0.0251\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0134\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0132\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0126\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0121\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0116\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0113\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0113\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0112\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0112\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0109\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0111\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0111\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0111\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0110\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0108\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0111\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0111\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0111\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0109\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0110\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0111\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0109\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0111\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0113\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0117\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0414 - val_loss: 0.0222\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0136\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0136\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0135\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0135\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0136\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0135\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0135\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0134\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0135\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0134\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0137\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0134\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0134\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0138\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0134\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0136\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0135\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0135\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0135\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0135\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0781 - val_loss: 0.0520\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0362 - val_loss: 0.0286\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0227 - val_loss: 0.0223\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0205\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0182\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0170\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0161\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0153\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0147\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0142\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0140\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0138\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0136\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0135\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0134\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0134\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0135\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0134\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0134\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0134\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0136\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0135\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0135\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0136\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0136\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0137\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0458 - val_loss: 0.0264\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0173\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0169\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0168\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0156 - val_loss: 0.0166\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 7ms/step - loss: 0.0154 - val_loss: 0.0166\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0165\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0165\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0164\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0163\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0163\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0161\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0148 - val_loss: 0.0161\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0161\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0159\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0160\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0160\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0159\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0158\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0158\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0158\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0143 - val_loss: 0.0158\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0158\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0157\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0156\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0155\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0155\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0155\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0155\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0154\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0153\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0152\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0151\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0152\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0152\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0153\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0150\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0149\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0150\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0150\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0150\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0151\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0150\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0151\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0150\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0150\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0152\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0149\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0150\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0149\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0150\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0148\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0150\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0150\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0153\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0151\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0117 - val_loss: 0.0150\n",
            "layer: 18\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0680 - val_loss: 0.0423\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0342 - val_loss: 0.0217\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0214 - val_loss: 0.0179\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0168\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0159\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0161 - val_loss: 0.0153\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0150\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0147\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0145\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0143\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0142\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0140\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0134 - val_loss: 0.0138\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0137\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0136\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0139\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0137\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0136\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0139\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0137\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0136\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0129 - val_loss: 0.0138\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0135\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0134\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0135\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0126 - val_loss: 0.0135\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0134\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0134\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0134\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0133\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0133\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0135\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0136\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0135\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0134\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0133\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0134\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0134\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0134\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0134\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0600 - val_loss: 0.0303\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0157\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0159\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0154\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0160 - val_loss: 0.0148\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0144\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0154 - val_loss: 0.0141\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0139\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0138\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0137\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0135\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0130\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0130\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0129\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0125\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0122\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0118\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0120\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0117\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0113\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0114\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0114\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0112\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0132 - val_loss: 0.0112\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0112\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0119\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0110\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0120\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0116\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0112\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0115\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0119\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0120\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0121\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0118\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0116\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0114\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0470 - val_loss: 0.0199\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0136\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0136\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0135\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0135\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0137\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0136\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0119 - val_loss: 0.0136\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0137\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0134\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0133\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0118 - val_loss: 0.0134\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0133\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0135\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0140\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0115 - val_loss: 0.0133\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0137\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0133\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0137\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0135\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0136\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0137\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0135\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0135\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0113 - val_loss: 0.0138\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0114 - val_loss: 0.0140\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 10ms/step - loss: 0.0368 - val_loss: 0.0196\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0144\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0172 - val_loss: 0.0138\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0166 - val_loss: 0.0136\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0133\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0159 - val_loss: 0.0133\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0131\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0130\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0130\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0129\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0150 - val_loss: 0.0129\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0128\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0127\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0146 - val_loss: 0.0126\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0145 - val_loss: 0.0126\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0125\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0126\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0125\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0125\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0124\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0124\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0125\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0124\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0124\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0123\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0124\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0122\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0122\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0122\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0123\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0123\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0123\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0123\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0133 - val_loss: 0.0123\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0124\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0124\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0124\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0123\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0290 - val_loss: 0.0188\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0170\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0164\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0160\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0157\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0155\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0153\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0152\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0151\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0150\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0150\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0126 - val_loss: 0.0149\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0149\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0149\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0149\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0149\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0149\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0149\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0149\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0125 - val_loss: 0.0149\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0148\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0149\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0149\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0149\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0149\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0149\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0149\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0148\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0149\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0149\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0149\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0121 - val_loss: 0.0149\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0122 - val_loss: 0.0149\n",
            "layer: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "oJ3NG-ME5shn",
        "outputId": "b9941d19-1554-4f89-e92c-9846b04ddece"
      },
      "source": [
        "# plot\n",
        "n = np.arange(0,max_layer)\n",
        "plt.plot(n,y_arr,c = 'red', label ='test error') \n",
        "\n",
        "plt.plot(n,x_arr,c = 'blue', label = 'train error')\n",
        "plt.xlabel('numer of layers')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train error vs test error in 18~9 data')\n",
        "plt.savefig('train error vs test error in 18~9')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f368eaf8d50>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDAMEzaLVmjo",
        "outputId": "c229cd03-a87e-4a0d-efd7-be900793b46f"
      },
      "source": [
        "#\n",
        "for train, test in skf.split(x,y_cat): \n",
        "  model = Sequential()\n",
        "  model.add(Dense(8,input_dim = 7, activation= 'relu'))\n",
        "  model.add(Dense(12,activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss = 'mean_squared_error', optimizer = 'adam') \n",
        "  model.fit(x[train],y[train], validation_split= 0.2, epochs = 300, batch_size= 10, callbacks = [ESC])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0540 - val_loss: 0.0346\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0170\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0156\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0153\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0151\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0149\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0146\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0144\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0142\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0140\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0138\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0138\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0136\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0135\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0134\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0131 - val_loss: 0.0134\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0134\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0134\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0134\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0134\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0134\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0134\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0134\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0568 - val_loss: 0.0275\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0136\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0137\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0133\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0154 - val_loss: 0.0129\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0125\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0123\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0122\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0122\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0121\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0122\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0141 - val_loss: 0.0117\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0118\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0139 - val_loss: 0.0117\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0117\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0116\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0113\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0115\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0113\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0114\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0112\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0112\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0111\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0111\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0115\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0109\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0114\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0113\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0110\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0112\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0115\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0117\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0118\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0115\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0116\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0113\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0407 - val_loss: 0.0222\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0173 - val_loss: 0.0146\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0143\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0140\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0139\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0139\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0139\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0139\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0138\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0138\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0137\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0138\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0140\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0138\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0139\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0144\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0137\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0144\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0137\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0143\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0139\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0141\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0142\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0141\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0142\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0143\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0147\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0139\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0143\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0222 - val_loss: 0.0188\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0162\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0151\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0144\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0139\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0138\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0137\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0136\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0136\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0135\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0134\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0134\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0137\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0135\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0135\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0127 - val_loss: 0.0135\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0135\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0133\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0133\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0134\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0135\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0137\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0135\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0135\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0135\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0135\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0135\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0122 - val_loss: 0.0136\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0136\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0588 - val_loss: 0.0390\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0271\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0239\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0216\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0201\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0165 - val_loss: 0.0191\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0157 - val_loss: 0.0182\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0175\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0168\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - val_loss: 0.0161\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0136 - val_loss: 0.0159\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0154\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0131 - val_loss: 0.0152\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0150\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0148\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0147\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0146\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0145\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0145\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0145\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0145\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0145\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0145\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0144\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0144\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0145\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0144\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0144\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0144\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0144\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0143\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0144\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0144\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0146\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0144\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0144\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0144\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0144\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0145\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0145\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HsHRJIxfVmnE",
        "outputId": "f2a76053-f208-411d-ec96-3f858e5fde97"
      },
      "source": [
        "# plot\n",
        "\n",
        "# about last fold\n",
        "# y_predict = model.predict(x[test])\n",
        "\n",
        "# about all data\n",
        "y_predict = model.predict(x) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# about last fold\n",
        "# plt.scatter(y[test], y_predict, alpha=0.4)\n",
        "\n",
        "# about all data\n",
        "plt.scatter(y, y_predict, alpha=0.4)\n",
        "\n",
        "plt.plot([0,1],[0,1], c = 'red')\n",
        "plt.xlabel(\"Actual population\")\n",
        "plt.ylabel(\"Predicted population\")\n",
        "plt.title(\"Deep Neural Network dense 12 in 18~9data\")\n",
        "plt.savefig('DNN_test_18~9.png')\n",
        "plt.show() "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNrAEHm3h0up",
        "outputId": "66c30d0c-b9f6-422a-dbba-cdabd75e8087"
      },
      "source": [
        "list_y = y.tolist()\n",
        "list_predicty = []\n",
        "\n",
        "for i in range(len(list_y)):\n",
        "    list_predicty.append(y_predict[i].item())\n",
        "diff = []\n",
        "for i in range(len(list_y)):\n",
        "    diff.append(list_y[i] - list_predicty[i])\n",
        "diff"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.007310084841931852,\n",
              " 0.07137573461130803,\n",
              " 0.1388188128630924,\n",
              " -0.10033969838498177,\n",
              " -0.24283126660281296,\n",
              " 0.15412028716744441,\n",
              " -0.0446800289199194,\n",
              " -0.0934440634443178,\n",
              " -0.21392914620457548,\n",
              " 0.08026741823584821,\n",
              " 0.036644046359238014,\n",
              " 0.20787050725134942,\n",
              " 0.12532995018944337,\n",
              " 0.026528204387290866,\n",
              " -0.05063147675850527,\n",
              " -0.13773581765238374,\n",
              " 0.0011034411523666854,\n",
              " -0.06895427985865998,\n",
              " -0.09138618922959432,\n",
              " -0.07310196598089855,\n",
              " 0.0021831749657105215,\n",
              " -0.06802526323647837,\n",
              " -0.016687565653559444,\n",
              " -0.05825716762880112,\n",
              " 0.173145004086524,\n",
              " 0.23429870153023152,\n",
              " 0.08090454634867844,\n",
              " 0.1047790523590097,\n",
              " 0.06650286256070459,\n",
              " -0.083506759296122,\n",
              " -0.18224914606828505,\n",
              " -0.07448996878210673,\n",
              " 0.12575414071722352,\n",
              " -0.07622848491318723,\n",
              " -0.040431692473074626,\n",
              " 0.059846045978301454,\n",
              " 0.05140679488257954,\n",
              " 0.07507596612308753,\n",
              " 0.027414680489155185,\n",
              " -0.011809838258386773,\n",
              " -0.016548652673432446,\n",
              " -0.03499657365849923,\n",
              " -0.07295724168566245,\n",
              " -0.10558474059509079,\n",
              " 0.22730521855136132,\n",
              " 0.10788994821128739,\n",
              " -0.10403837370592123,\n",
              " 0.02250851727291009,\n",
              " -0.04138260537643107,\n",
              " -0.10585265595790871,\n",
              " -0.1621322470232543,\n",
              " 0.017999390262686293,\n",
              " -0.10263692259046732,\n",
              " -0.021091277842340772,\n",
              " -0.08606934051528936,\n",
              " 0.1635193228024059,\n",
              " -0.0415070242359738,\n",
              " 0.113988045616287,\n",
              " 0.23140029398278184,\n",
              " 0.1844446983314686,\n",
              " -0.07132073692389104,\n",
              " -0.07408840438616532,\n",
              " -0.038838604105920105,\n",
              " 0.049190227139415565,\n",
              " 0.01519110554365355,\n",
              " 0.14936758495712943,\n",
              " -0.0572767605906582,\n",
              " 0.00815140727703445,\n",
              " 0.06847437379185983,\n",
              " 0.21967106606982667,\n",
              " 0.2075534736120711,\n",
              " -0.02341836675581191,\n",
              " 0.12971391993635945,\n",
              " 0.08353976591553225,\n",
              " 0.10822521175586841,\n",
              " 0.025018280703282547,\n",
              " 0.09120830035189642,\n",
              " -0.019177255138090932,\n",
              " -0.08359002255266129,\n",
              " -0.08091776202729603,\n",
              " 0.0005722641461591571,\n",
              " -0.08312805144864746,\n",
              " 0.00766048129972946,\n",
              " -0.032940811614260296,\n",
              " 0.037937037206097146,\n",
              " -0.08433190454335965,\n",
              " -0.1319606184182178,\n",
              " -0.16574758418325355,\n",
              " 0.05966654192996296,\n",
              " -0.14259949597809443,\n",
              " -0.2006309891082397,\n",
              " 0.05781586736465294,\n",
              " 0.04102569363014352,\n",
              " -0.06925502547319506,\n",
              " 0.2064053933876424,\n",
              " -0.04059339027932582,\n",
              " -0.10453329172723438,\n",
              " -0.05010619730361138,\n",
              " -0.08101919095104973,\n",
              " 0.15320694026121784,\n",
              " -0.027592449862045954,\n",
              " -0.03138983619035174,\n",
              " 0.000845495281936004,\n",
              " 3.4729257843701955e-05,\n",
              " -0.043951325986228335,\n",
              " -0.13085702880029232,\n",
              " -0.010226026854385173,\n",
              " 0.13785979085297106,\n",
              " -0.21956498349002812,\n",
              " 0.05503191583491451,\n",
              " -0.10451188812059975,\n",
              " 0.1018169941634236,\n",
              " 0.032072046835248946,\n",
              " -0.04532190430851707,\n",
              " -0.059438833642504796,\n",
              " 0.0842715752495149,\n",
              " -0.18801869939599278,\n",
              " 0.008760430148993748,\n",
              " -0.017237125969545908,\n",
              " 0.1296801370342755,\n",
              " 0.016441825544017352,\n",
              " 0.12370984788018996,\n",
              " 0.0036344824212533045,\n",
              " 0.02795984940625243,\n",
              " -0.01734661050758385,\n",
              " -0.11480669996083598,\n",
              " -0.053001372121509405,\n",
              " 0.15762171860194907,\n",
              " -0.18304371860439556,\n",
              " -0.06858595215186242,\n",
              " -0.011733701623209802,\n",
              " -0.01290352162914915,\n",
              " -0.03128940370469435,\n",
              " 0.014661535238196188,\n",
              " -0.05604876612127857,\n",
              " -0.03423936651092532,\n",
              " 0.15844486740446462,\n",
              " 0.020448872531939277,\n",
              " -0.07971621206580465,\n",
              " -0.03411912424326602,\n",
              " 0.015128063507494849,\n",
              " -0.06521379089236884,\n",
              " -0.06743892023696146,\n",
              " 0.008189883401246878,\n",
              " -0.05981544937782407,\n",
              " -0.05905381750815536,\n",
              " -0.09698676671683035,\n",
              " -0.07668433610754449,\n",
              " -0.07363340340572028,\n",
              " -0.05801039953821552,\n",
              " -0.0931641156494574,\n",
              " 0.12215358383433111,\n",
              " 0.18233877566686518,\n",
              " 0.12208901507169712,\n",
              " 0.05416697801425002,\n",
              " -0.08822648830225527,\n",
              " 0.08016604159156482,\n",
              " 0.12510436319297535,\n",
              " -0.04194523404188505,\n",
              " -0.06197564261407956,\n",
              " -0.10102876195838398,\n",
              " -0.11067482089921701,\n",
              " -0.03748856498774897,\n",
              " 0.07192455457159586,\n",
              " -0.12587146960979095,\n",
              " 0.02660917504437843,\n",
              " 0.03180191467004223,\n",
              " 0.04920081192540415,\n",
              " 0.1581000869333566,\n",
              " -0.20992086276521815,\n",
              " -0.11808750199489243,\n",
              " 0.19455046267530907,\n",
              " 0.06402110783670156,\n",
              " -0.0022531919892720964,\n",
              " -0.023622851075074502,\n",
              " 0.2660032748625658,\n",
              " -0.04439433656646166,\n",
              " -0.010651671178048105,\n",
              " 0.23281835346503832,\n",
              " 0.016485838083790533,\n",
              " -0.021767021865430614,\n",
              " 0.0710894778880623,\n",
              " -0.06368739930381317,\n",
              " 0.07766664854644478,\n",
              " 0.050681044640675854,\n",
              " 0.11508227189744102,\n",
              " 0.012440930275978368,\n",
              " 0.46085276155190036,\n",
              " 0.01966261671101116,\n",
              " -0.10147156604475943,\n",
              " 0.054079931203996234,\n",
              " 0.054925537507156064,\n",
              " 0.1286988717788874,\n",
              " 0.2432957514901959,\n",
              " -0.008090732013158575,\n",
              " 0.03760461727436726,\n",
              " 0.18005606552132192,\n",
              " -0.016115939222928755,\n",
              " 0.049646696424999304,\n",
              " 0.08558290426608273,\n",
              " 0.027904168846338617,\n",
              " 0.02982527114267436,\n",
              " 0.07394279059116915,\n",
              " -0.10026236186041737,\n",
              " -0.060204994571805004,\n",
              " -0.05153581524072104,\n",
              " 0.0004601939107102271,\n",
              " 0.04911066757619775,\n",
              " -0.010187777185126312,\n",
              " -0.11541998404812992,\n",
              " -0.12909410683145228,\n",
              " 0.17836352485207857,\n",
              " 0.06776948072028133,\n",
              " 0.11284757998343975,\n",
              " -0.013473403332640826,\n",
              " 0.03490630571325709,\n",
              " -0.1387181897635387,\n",
              " -0.054054603289205916,\n",
              " 0.0040149533034180285,\n",
              " 0.010473867587284358,\n",
              " 0.11433492953440755,\n",
              " -0.14463993197320119,\n",
              " -0.06225994054771258,\n",
              " 0.10539801595151144,\n",
              " -0.0737963030662685,\n",
              " -0.14727438407433205,\n",
              " -0.09018493062497714,\n",
              " -0.08802689090349802,\n",
              " -0.03520554714091789,\n",
              " -0.09444077107609505,\n",
              " -0.1567316071468138,\n",
              " -0.1553499455260014,\n",
              " 0.051514376856110905,\n",
              " -0.08571375212356822,\n",
              " 0.08756095609079473,\n",
              " -0.06983584724110128,\n",
              " -0.10084698684391594,\n",
              " 0.021792271029155874,\n",
              " -0.07374941186320477,\n",
              " 0.013095768241373429,\n",
              " -0.05467949108171116,\n",
              " 0.07359671789675509,\n",
              " 0.047213252566704667,\n",
              " -0.04431919090020031,\n",
              " 0.1316796836371864,\n",
              " 0.024524757580115242,\n",
              " -0.0461310118514294,\n",
              " -0.01973614642966215,\n",
              " -0.10380555075911285,\n",
              " -0.05505171607251397,\n",
              " -0.06229795559499038,\n",
              " -0.15752475240111594,\n",
              " -0.1614518287097608,\n",
              " -0.1744081001984006,\n",
              " -0.06707413125922873,\n",
              " -0.013149026346908593,\n",
              " -0.11685904943754538,\n",
              " 0.15400545380944441,\n",
              " 0.13760660262502483,\n",
              " -0.10853304657431367,\n",
              " -0.04677124065518057,\n",
              " 0.29025867117995807,\n",
              " -0.07185077263881634,\n",
              " -0.025362074506574905,\n",
              " -0.051870799023851055,\n",
              " -0.1013168732841341,\n",
              " 0.0087233414075652,\n",
              " 0.003959157766024901,\n",
              " 0.14092841377212356,\n",
              " -0.12205672331573139,\n",
              " -0.11657708080230572,\n",
              " 0.08481519513932412,\n",
              " -0.080805809893291,\n",
              " 0.20322511394750303,\n",
              " 0.0557895631061156,\n",
              " -0.021183945447712765,\n",
              " 0.025614704974788904,\n",
              " 0.134055404232991,\n",
              " 0.7026672959327698,\n",
              " 0.23103068482097244,\n",
              " 0.2891550090268289,\n",
              " 0.006790823824074532,\n",
              " 0.15422008932378373,\n",
              " -0.12177553381280395,\n",
              " 0.03856294378621705,\n",
              " 0.26468979476598653,\n",
              " -0.04335964889036875,\n",
              " 0.17130184523426228,\n",
              " -0.06351977141813786,\n",
              " 0.28778714170087405,\n",
              " -0.09713185081344111,\n",
              " 0.10319949814642493,\n",
              " -0.11400607767404608,\n",
              " 0.075781787742626,\n",
              " 0.02764774129587977,\n",
              " -0.042015335353619954,\n",
              " -0.12438373773269734,\n",
              " -0.0919519967940371,\n",
              " 0.19836834442963946,\n",
              " -0.004340074971213748,\n",
              " 0.10140716314736997,\n",
              " -0.07503040205872075,\n",
              " -0.10394251609222113,\n",
              " -0.01528612490966974,\n",
              " -0.04907809271623709,\n",
              " 0.08290845070099384,\n",
              " -0.0076737208894046005,\n",
              " -0.0023537732401511524,\n",
              " 0.05217493351212055,\n",
              " 0.0969819653480597,\n",
              " -0.14659265823490425,\n",
              " -0.10962295338726424,\n",
              " 0.07411582860339128,\n",
              " -0.15545810304418678,\n",
              " 0.06004549342516102,\n",
              " -0.029299649906906117,\n",
              " -0.06941836269347479,\n",
              " -0.0045006875145304215,\n",
              " -0.1520469766305121,\n",
              " -0.11083243934081169,\n",
              " -0.09710270670439433,\n",
              " -0.005007374516132701,\n",
              " 0.13697731816971603,\n",
              " 0.09633208493915313,\n",
              " -0.04236496848875082,\n",
              " -0.15991329131963217,\n",
              " -0.0009795376184542626,\n",
              " 0.029912720746097632,\n",
              " 0.01682909596808166,\n",
              " -0.0395691986311012,\n",
              " 0.04111441025939283,\n",
              " 0.08468298498075932,\n",
              " 0.13872497572756193,\n",
              " -0.09691742553720564,\n",
              " -0.051361068306411184,\n",
              " -0.1525585612196041,\n",
              " 0.15872606181786697,\n",
              " 0.03120626912814145,\n",
              " 0.12952276598774648,\n",
              " 0.04679874802449191,\n",
              " 0.047908136526789546,\n",
              " -0.09619785985214624,\n",
              " -0.1875729858571665,\n",
              " 0.06561964624460825,\n",
              " -0.17613942648364367,\n",
              " 0.0825256840057208,\n",
              " -0.11308356261312469,\n",
              " -0.13782900586217958,\n",
              " 0.008527906338148455,\n",
              " -0.07748298262446068,\n",
              " -0.05585144988807675,\n",
              " 0.13338513816851794,\n",
              " 0.05517004846893919,\n",
              " 0.01961508788991928,\n",
              " -0.08874190681704336,\n",
              " 0.17847520764216662,\n",
              " -0.0220564378513472,\n",
              " 0.10803117917215188,\n",
              " -0.0859551560755748,\n",
              " -0.06038677833813655,\n",
              " -0.02586227126355145,\n",
              " 0.016160387003912202,\n",
              " -0.04978814667363815,\n",
              " 0.08916500388331167,\n",
              " -0.14393991593439062,\n",
              " -0.017563349792419303,\n",
              " -0.0314615788746867,\n",
              " 0.0801678795626849,\n",
              " -0.095084482941492,\n",
              " 0.022269473983234644,\n",
              " 0.02086014445567347,\n",
              " 0.08292748265073202,\n",
              " -0.1125015121007768,\n",
              " -0.04050245932940849,\n",
              " -0.03714306664559203,\n",
              " -0.15145235321338477,\n",
              " -0.11004966794224856,\n",
              " -0.18852808027135887,\n",
              " -0.07608402758281974,\n",
              " 0.21042905913526966,\n",
              " 0.2518997881313899,\n",
              " 0.11706527930880478,\n",
              " -0.10359681921076097,\n",
              " 0.1792653923694405,\n",
              " -0.054950646870344955,\n",
              " 0.2695470918199019,\n",
              " -0.13476254169805685,\n",
              " -0.0600030649043409,\n",
              " 0.03950784605050431,\n",
              " 0.17823579196185224,\n",
              " -0.023206247862384677,\n",
              " -0.076918200903495,\n",
              " 0.18512953146908784,\n",
              " -0.1786711515055421,\n",
              " 0.045838397851046264,\n",
              " -0.10069121200623496,\n",
              " -0.09732240588475849,\n",
              " 0.03458338864980315,\n",
              " 0.010674622409660939,\n",
              " -0.08572152337018177,\n",
              " -0.05200417428152973,\n",
              " 0.019930499815407232,\n",
              " 0.05919417844247982,\n",
              " -0.09960111962563534,\n",
              " 0.05205668058134727,\n",
              " -0.03971179515029677,\n",
              " -0.16188675143892797,\n",
              " -0.050116241934524935,\n",
              " 0.3468539991695554,\n",
              " -0.0721939129079995,\n",
              " 0.02494284464787952,\n",
              " -0.04743654677998871,\n",
              " -0.017644118701253347,\n",
              " 0.1060774424845583,\n",
              " 0.14841247544812025,\n",
              " 0.1700603169218834,\n",
              " -0.18277719911538187,\n",
              " -0.034542244461395866,\n",
              " -0.16424998949742337,\n",
              " -0.1420021474049912,\n",
              " -0.07478260481160956,\n",
              " -0.035925358673733476,\n",
              " -0.029538528456605234,\n",
              " 0.11348984584354893]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL2NZKbxvIkc"
      },
      "source": [
        "df1['diff'] = diff"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "kOIWbCUl2TVQ",
        "outputId": "35a489ee-235c-4e25-f15e-c1b03ba16508"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>affnc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>population</th>\n",
              "      <th>pop_cat</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>가락1동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.164634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.022764</td>\n",
              "      <td>0.299870</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.007310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>가락2동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.056098</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.303859</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.071376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>가락본동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.154472</td>\n",
              "      <td>0.045161</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.040650</td>\n",
              "      <td>0.426756</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.138819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>가리봉동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.293902</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.105551</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.100340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>가산동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.335484</td>\n",
              "      <td>0.343902</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.549815</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.242831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dong  highway      ffnc      fsnc  ...      afsc  population  pop_cat      diff\n",
              "0  가락1동      0.0  0.225806  0.164634  ...  0.022764    0.299870      3.0 -0.007310\n",
              "1  가락2동      0.0  0.161290  0.024390  ...  0.043902    0.303859      4.0  0.071376\n",
              "2  가락본동      0.0  0.032258  0.146341  ...  0.040650    0.426756      5.0  0.138819\n",
              "3  가리봉동      0.0  0.032258  0.006098  ...  0.034146    0.105551      2.0 -0.100340\n",
              "4   가산동      0.0  1.000000  1.000000  ...  0.058537    0.549815      5.0 -0.242831\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdswqfmk2TZ3"
      },
      "source": [
        "a = df1['diff'].sort_values()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_z2YVAtwC7v"
      },
      "source": [
        "df1_sort = df1.sort_values(by = df1.columns[-1], ascending= False )"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "j_zeaYq2yCbG",
        "outputId": "23fb9f23-4247-43ee-c25b-edb188da6ae8"
      },
      "source": [
        "df1_sort"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>affnc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>population</th>\n",
              "      <th>pop_cat</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>역삼1동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>0.103659</td>\n",
              "      <td>0.211382</td>\n",
              "      <td>0.058065</td>\n",
              "      <td>0.060976</td>\n",
              "      <td>0.167480</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.702667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>서교동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.017073</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.666805</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.460853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>화곡1동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.010976</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.556467</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.346854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>신촌동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079268</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012903</td>\n",
              "      <td>0.032927</td>\n",
              "      <td>0.029268</td>\n",
              "      <td>0.500452</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.290259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>역촌동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.032520</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.017073</td>\n",
              "      <td>0.050407</td>\n",
              "      <td>0.485855</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.289155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>둔촌1동</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.012195</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.200631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>삼청동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109677</td>\n",
              "      <td>0.084146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002769</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.209921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>가회동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.109677</td>\n",
              "      <td>0.084146</td>\n",
              "      <td>0.004878</td>\n",
              "      <td>0.013113</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.213929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>명동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.741935</td>\n",
              "      <td>0.018293</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.238710</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.026016</td>\n",
              "      <td>0.183680</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.219565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>가산동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.335484</td>\n",
              "      <td>0.343902</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.549815</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.242831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>424 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     dong  highway      ffnc      fsnc  ...      afsc  population  pop_cat      diff\n",
              "278  역삼1동      0.0  0.129032  0.103659  ...  0.167480    1.000000      5.0  0.702667\n",
              "187   서교동      0.0  0.000000  0.006098  ...  0.048780    0.666805      5.0  0.460853\n",
              "408  화곡1동      0.0  0.032258  0.000000  ...  0.066667    0.556467      5.0  0.346854\n",
              "261   신촌동      0.0  0.000000  0.079268  ...  0.029268    0.500452      5.0  0.290259\n",
              "280   역촌동      0.0  0.032258  0.006098  ...  0.050407    0.485855      5.0  0.289155\n",
              "..    ...      ...       ...       ...  ...       ...         ...      ...       ...\n",
              "90   둔촌1동      0.5  0.000000  0.000000  ...  0.016260    0.002422      1.0 -0.200631\n",
              "169   삼청동      0.0  0.064516  0.000000  ...  0.000000    0.002769      1.0 -0.209921\n",
              "8     가회동      0.0  0.129032  0.000000  ...  0.004878    0.013113      1.0 -0.213929\n",
              "108    명동      0.0  0.741935  0.018293  ...  0.026016    0.183680      2.0 -0.219565\n",
              "4     가산동      0.0  1.000000  1.000000  ...  0.058537    0.549815      5.0 -0.242831\n",
              "\n",
              "[424 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES8qrrl8vuRq"
      },
      "source": [
        "df1_sort.to_excel('sort_1829df.xlsx')"
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}