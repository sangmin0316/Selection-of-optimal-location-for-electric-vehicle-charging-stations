{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_9218.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x85oa8X9Xzqj"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_excel('f_029df.xlsx')\n",
        "df2 = pd.read_excel('f_9218df.xlsx')\n",
        "df3 = pd.read_excel('f_18224df.xlsx')\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "Nhd-R_lpgvmt",
        "outputId": "85d46a1b-0e77-4021-e1c1-b6a9ff973494"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>dong</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>ffc</th>\n",
              "      <th>nfnc</th>\n",
              "      <th>nfc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>nsnc</th>\n",
              "      <th>nsc</th>\n",
              "      <th>총생활인구수</th>\n",
              "      <th>affnc</th>\n",
              "      <th>affc</th>\n",
              "      <th>anfnc</th>\n",
              "      <th>anfc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>ansnc</th>\n",
              "      <th>ansc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>가락1동</td>\n",
              "      <td>127.108235</td>\n",
              "      <td>37.495329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.164634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.322362</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.022764</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.034783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>가락2동</td>\n",
              "      <td>127.130643</td>\n",
              "      <td>37.495860</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.320622</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.056098</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.130435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>가락본동</td>\n",
              "      <td>127.121640</td>\n",
              "      <td>37.497217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.154472</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.445918</td>\n",
              "      <td>0.045161</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.040650</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.078261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>가리봉동</td>\n",
              "      <td>126.888257</td>\n",
              "      <td>37.482555</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108998</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.293902</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.234783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>가산동</td>\n",
              "      <td>126.884341</td>\n",
              "      <td>37.476835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.562965</td>\n",
              "      <td>0.335484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.343902</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.286957</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  dong  ...      afsc  ansnc      ansc\n",
              "0           0             0  가락1동  ...  0.022764  0.012  0.034783\n",
              "1           1             1  가락2동  ...  0.043902  0.064  0.130435\n",
              "2           2             2  가락본동  ...  0.040650  0.064  0.078261\n",
              "3           3             3  가리봉동  ...  0.034146  0.392  0.234783\n",
              "4           4             4   가산동  ...  0.058537  0.408  0.286957\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z50DrnmGgvu_"
      },
      "source": [
        "# 필요없는 column 삭제\n",
        "df1 = df1.drop('Unnamed: 0', axis = 1)\n",
        "df1 = df1.drop('Unnamed: 0.1', axis = 1)\n",
        "df1 = df1.drop('X', axis = 1)\n",
        "df1 = df1.drop('Y', axis = 1)\n",
        "\n",
        "df2 = df2.drop('Unnamed: 0', axis = 1)\n",
        "df2 = df2.drop('Unnamed: 0.1', axis = 1)\n",
        "df2 = df2.drop('X', axis = 1)\n",
        "df2 = df2.drop('Y', axis = 1)\n",
        "\n",
        "df3 = df3.drop('Unnamed: 0', axis = 1)\n",
        "df3 = df3.drop('Unnamed: 0.1', axis = 1)\n",
        "df3 = df3.drop('X', axis = 1)\n",
        "df3 = df3.drop('Y', axis = 1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_hUaB84q5fI"
      },
      "source": [
        "# 전에 heatmap을 그린것을 보면 ffc는 데이터가 너무 없어서 -값 내지는 매우 작은값을 보였습니다.\n",
        "# 머신러닝돌릴때는 ffc와 affc도 drop합시다.\n",
        "df2 = df2.drop('ffc', axis = 1)\n",
        "df2 = df2.drop('affc', axis = 1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcS-86vCCL8y"
      },
      "source": [
        "# null값을 0으로 채워둡니다.\n",
        "df2 = df2.fillna(0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmY7fPN0scg-"
      },
      "source": [
        "a = df2['총생활인구수'].values\n",
        "df2 = df2.drop('총생활인구수', axis = 1)\n",
        "df2['population'] = a"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlIz9cBci8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "b226bc8a-c100-4a4a-ec60-3915c7f39f11"
      },
      "source": [
        "df2"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>nfnc</th>\n",
              "      <th>nfc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>nsnc</th>\n",
              "      <th>nsc</th>\n",
              "      <th>affnc</th>\n",
              "      <th>anfnc</th>\n",
              "      <th>anfc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>ansnc</th>\n",
              "      <th>ansc</th>\n",
              "      <th>population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>가락1동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.022764</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.034783</td>\n",
              "      <td>0.155581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>가락2동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.056098</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.154967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>가락본동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.154472</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.045161</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.040650</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.078261</td>\n",
              "      <td>0.264574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>가리봉동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.293902</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.234783</td>\n",
              "      <td>0.062857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>가산동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.335484</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.343902</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.636785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>효창동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.056911</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.025806</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.067073</td>\n",
              "      <td>0.060163</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.208696</td>\n",
              "      <td>0.041038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>후암동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030488</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>0.051613</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029268</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.026087</td>\n",
              "      <td>0.062667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>휘경1동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042683</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.099187</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.234783</td>\n",
              "      <td>0.093562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>휘경2동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.030488</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.064634</td>\n",
              "      <td>0.091057</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.093976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>흑석동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079268</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.060976</td>\n",
              "      <td>0.169106</td>\n",
              "      <td>0.024</td>\n",
              "      <td>0.139130</td>\n",
              "      <td>0.188528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>424 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     dong  highway      ffnc  nfnc  ...      afsc  ansnc      ansc  population\n",
              "0    가락1동      0.0  0.225806  0.00  ...  0.022764  0.012  0.034783    0.155581\n",
              "1    가락2동      0.0  0.161290  0.00  ...  0.043902  0.064  0.130435    0.154967\n",
              "2    가락본동      0.0  0.032258  0.00  ...  0.040650  0.064  0.078261    0.264574\n",
              "3    가리봉동      0.0  0.032258  0.05  ...  0.034146  0.392  0.234783    0.062857\n",
              "4     가산동      0.0  1.000000  0.20  ...  0.058537  0.408  0.286957    0.636785\n",
              "..    ...      ...       ...   ...  ...       ...    ...       ...         ...\n",
              "419   효창동      0.0  0.000000  0.00  ...  0.060163  0.032  0.208696    0.041038\n",
              "420   후암동      0.0  0.000000  0.00  ...  0.024390  0.040  0.026087    0.062667\n",
              "421  휘경1동      0.0  0.000000  0.00  ...  0.099187  0.016  0.234783    0.093562\n",
              "422  휘경2동      0.0  0.096774  0.10  ...  0.091057  0.024  0.286957    0.093976\n",
              "423   흑석동      0.0  0.032258  0.05  ...  0.169106  0.024  0.139130    0.188528\n",
              "\n",
              "[424 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "u5QtwbPMktjS",
        "outputId": "9bbc484b-92ed-4947-c6cd-7b684587e6e8"
      },
      "source": [
        "# 데이터들의 histgram을 봅시다.\n",
        "import matplotlib.pyplot as plt\n",
        "df2.hist(bins = 50, figsize = (20,15))\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8dnBadNeVmcs",
        "outputId": "654b8075-6563-4bb4-ca60-e13bbe3f05bb"
      },
      "source": [
        "# population 데이터가 class값으로 들어가게 될것입니다.\n",
        "# 우리는 population data를 치우치지 않게 여러 set 뽑아주는 StratifiedKFold를 하고 싶습니다.\n",
        "# population을 5개의 구역으로 나눠줬습니다. kfold를 할때 각 구역에서 일정한 값들이 뽑히게 할것입니다.\n",
        "\n",
        "# pd.cut을 이용하여 population을 5개의 구역으로 나눈것을 pop_cut이라는 column에 담았습니다,\n",
        "df2[\"pop_cat\"] = pd.cut(df2[\"population\"],\n",
        "                              bins = [-1.0, 0.1, 0.2, 0.3, 0.4, 1.1],\n",
        "                              labels = [1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "df2[\"pop_cat\"].hist()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f72fa785850>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlU83M8ywoYe",
        "outputId": "219576cc-9e18-4d7a-f074-e01ac0969965"
      },
      "source": [
        "# average, standard deviation\n",
        "import numpy as np\n",
        "a = [1,3,5,7,9]\n",
        "b = sum(a)/5\n",
        "c = b*np.ones(5)\n",
        "d = np.sqrt(sum((a - c)**2)/5)\n",
        "print(b)\n",
        "print(d)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n",
            "2.8284271247461903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q3OqwzhW1uq",
        "outputId": "efac3056-0eca-4f57-954f-a20b4be5d929"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# seed를 정해줍니다.\n",
        "seed = 100\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "data = df2.values\n",
        "x = data[:,1:-2].astype(float)  # feature\n",
        "y = data[:,-2].astype(float)   # population\n",
        "y_cat = data[:,-1].astype(float) # pop_cut\n",
        "\n",
        "#  StratifiedKFold\n",
        "n_fold = 5\n",
        "skf = StratifiedKFold(n_splits = n_fold, shuffle = True, random_state = seed)\n",
        "  \n",
        "# 에러를 담기위해 먼저 빈 array를 만들었습니다.  \n",
        "test_error_set = []  \n",
        "train_error_set = [] \n",
        "\n",
        "# valiation loss가 patience만큼 반복해도 변하지 않거나 나빠지면 학습을 중단하게 설정합니다.  \n",
        "# patience 조정가능!\n",
        "ESC = EarlyStopping(monitor = 'val_loss', patience = 5) \n",
        "\n",
        "for train, test in skf.split(x,y_cat): # StratifiedKFold로 나눈 데이터 셋을 받습니다. n_fold가 5이므로 for문은 5번 돌것입니다.\n",
        "  model = Sequential()\n",
        "  model.add(Dense(7,input_dim = 15, activation= 'relu'))\n",
        "  model.add(Dense(1,activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss = 'mean_squared_error', optimizer = 'adam') \n",
        "  model.fit(x[train],y[train], validation_split= 0.2, epochs = 300, batch_size= 10, callbacks = [ESC])\n",
        "  # fold별로 error를 받아줘서 위에 만든 빈 array에 담아줍니다.\n",
        "  train_error = mean_squared_error(y[train], model.predict(x[train])) \n",
        "  test_error = mean_squared_error(y[test], model.predict(x[test]))\n",
        "  train_error_set.append(train_error)\n",
        "  test_error_set.append(test_error)\n",
        "# error들의 평균과 표준편차를 구해줍니다.\n",
        "average_train_error = sum(train_error_set)/5\n",
        "ate1 = average_train_error*np.ones(5)\n",
        "train_standard_deviation = np.sqrt(sum((train_error_set - ate1)**2)/5)\n",
        "average_test_error = sum(test_error_set)/5\n",
        "ate2 = average_test_error*np.ones(5)\n",
        "test_standard_deviation = np.sqrt(sum((test_error_set - ate2)**2)/5)\n",
        "\n",
        "print('train:',average_train_error,train_standard_deviation)\n",
        "print('test:',average_test_error,test_standard_deviation)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0357 - val_loss: 0.0240\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0266 - val_loss: 0.0192\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0161\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - val_loss: 0.0141\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0159 - val_loss: 0.0129\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0122\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0119\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0118\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - val_loss: 0.0117\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0117\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0309 - val_loss: 0.0265\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0236 - val_loss: 0.0208\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0187 - val_loss: 0.0169\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - val_loss: 0.0145\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0131\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0123\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0118\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0116\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0116\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0115\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0115\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0388 - val_loss: 0.0188\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0281 - val_loss: 0.0135\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0102\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0084\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0174 - val_loss: 0.0073\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0069\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0067\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0149 - val_loss: 0.0066\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0067\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0067\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0068\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0069\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0069\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0378 - val_loss: 0.0162\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0142\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0112\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0213 - val_loss: 0.0099\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0089\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0175 - val_loss: 0.0082\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0079\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0077\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0076\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0074\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0073\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0072\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0071\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0070\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0071\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0069\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0069\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0069\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0068\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0068\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0067\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0066\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0066\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0065\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0065\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0065\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0064\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0064\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0063\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0063\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0062\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0063\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0063\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0062\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0062\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0061\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0061\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0061\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0060\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0060\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0060\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0060\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0060\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0060\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0060\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0060\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0060\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0060\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0060\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0059\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0059\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0059\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0059\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0059\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0059\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0059\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0059\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0058\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0059\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0058\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0058\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0059\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0059\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0058\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0058\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0058\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0058\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0058\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0058\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0305 - val_loss: 0.0254\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0238 - val_loss: 0.0203\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0193 - val_loss: 0.0169\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0148\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0136\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0129\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0123\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0122\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0122\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0122\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "train: 0.011205058465614579 0.001993323909917846\n",
            "test: 0.012206404434047422 0.0038154494988798283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLhNvGGYVme8"
      },
      "source": [
        "# 위에서 만든 모델을 바탕으로 layer 수와 node 갯수를 변수로 받는 함수를 만들어줍니다.\n",
        "\n",
        "def construct_layer(layer_num,node_num):\n",
        "  test_error_set = []  \n",
        "  train_error_set = []  \n",
        "  \n",
        "  for train, test in skf.split(x,y_cat):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(node_num,input_dim = 15, activation= 'relu'))\n",
        "    model.add(Dense(layer_num,activation = 'relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss = 'mean_squared_error', optimizer = 'adam') \n",
        "    model.fit(x[train],y[train], validation_split= 0.2, epochs = 300, batch_size= 10, callbacks = [ESC])\n",
        "    train_error = mean_squared_error(y[train], model.predict(x[train]))\n",
        "    test_error = mean_squared_error(y[test], model.predict(x[test]))\n",
        "    train_error_set.append(train_error)\n",
        "    test_error_set.append(test_error)\n",
        "  \n",
        "  average_train_error = sum(train_error_set)/5\n",
        "  ate1 = average_train_error*np.ones(5)\n",
        "  train_standard_deviation = np.sqrt(sum((train_error_set - ate1)**2)/5)\n",
        "  average_test_error = sum(test_error_set)/5\n",
        "  ate2 = average_test_error*np.ones(5)\n",
        "  test_standard_deviation = np.sqrt(sum((test_error_set - ate2)**2)/5)\n",
        "\n",
        "  return [average_train_error, train_standard_deviation,average_test_error,test_standard_deviation]  "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2DT3zJ51v-d",
        "outputId": "be5e8c07-b157-48a9-f0be-0ae9c43a6748"
      },
      "source": [
        "a = construct_layer(1,15)\n",
        "print(a)\n",
        "#결과가 list로 잘 출력이 되네요!"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0338 - val_loss: 0.0238\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0249 - val_loss: 0.0191\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0206 - val_loss: 0.0161\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0141\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0157 - val_loss: 0.0129\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0122\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0119\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0118\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0130 - val_loss: 0.0117\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0129 - val_loss: 0.0117\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0288 - val_loss: 0.0250\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0227 - val_loss: 0.0200\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0165\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0142\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0121\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0117 - val_loss: 0.0117\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0115\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0115\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0114\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0697 - val_loss: 0.0215\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0136\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0109\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0090\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0185 - val_loss: 0.0078\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0071\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0068\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0067\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0066\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0067\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0067\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0068\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0068\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0069\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0186 - val_loss: 0.0125\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0137 - val_loss: 0.0112\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0096\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0090\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0084\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0080\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0078\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0073\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0072\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0071\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0071\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0071\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0069\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0069\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0069\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0071\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0302 - val_loss: 0.0252\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0202\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0192 - val_loss: 0.0169\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0163 - val_loss: 0.0147\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0135\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0133 - val_loss: 0.0128\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0123\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0122\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0122\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0122\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "[0.011243764127806458, 0.001908017890963878, 0.011851779481720899, 0.00438171773946633]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJtsW1GqVmhR",
        "outputId": "4d261aea-ac72-42fa-ec30-c47c5e5069d3"
      },
      "source": [
        "x_arr = [] # train error\n",
        "y_arr = [] # test error\n",
        "# hidden layer의 node수를 7로 해두고 층을 계속 쌓았을때 loss가 어떻게 변하는지 그려봅시다.\n",
        "max_layer = 20\n",
        "for i in range(0,max_layer):\n",
        "  a = construct_layer(i,16)\n",
        "  x_arr.append(a[0])\n",
        "  y_arr.append(a[2])\n",
        "  print('layer:',i)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0320\n",
            "layer: 0\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0117 - val_loss: 0.0072\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0069\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0068\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0068\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0067\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0067\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0066\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0065\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0067\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0064\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0066\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0066\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0065\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0064\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0064\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0065\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0067 - val_loss: 0.0064\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0064\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0064\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0063\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0063\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0064\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0064\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0065\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0063\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0288 - val_loss: 0.0250\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0200\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0183 - val_loss: 0.0165\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0152 - val_loss: 0.0142\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0129\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0121\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0117\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0115\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - val_loss: 0.0115\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0114\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0114\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0346 - val_loss: 0.0176\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0130\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0223 - val_loss: 0.0100\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0083\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0172 - val_loss: 0.0073\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0068\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0066\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0066\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0067\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0067\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0068\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0144 - val_loss: 0.0069\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0069\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 17s 609ms/step - loss: 0.0212 - val_loss: 0.0199\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0174\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0147\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0138\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0134 - val_loss: 0.0124\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0113\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0107\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0097\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0091\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0088\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0084\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0083\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0080\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0074\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0071\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0070\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0069\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0066\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0067\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0063\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0063\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0064\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0063\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0064\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0063\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0063\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0063\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0060\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0063\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0065\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0066\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0063\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0064\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0299 - val_loss: 0.0252\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0202\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - val_loss: 0.0168\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0163 - val_loss: 0.0147\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0144 - val_loss: 0.0135\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0128\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0126 - val_loss: 0.0124\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0122\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0122\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0122\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0120 - val_loss: 0.0122\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0122\n",
            "layer: 1\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0452 - val_loss: 0.0299\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0216\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0226 - val_loss: 0.0174\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0189 - val_loss: 0.0147\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0132\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0124\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0120\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0135 - val_loss: 0.0118\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0118\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0118\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0118\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0118\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0186 - val_loss: 0.0142\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0111\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0092\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0084\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.0073\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0069\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0064\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0063\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0061\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0060\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0059\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0059\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0057\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0056\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0054 - val_loss: 0.0054\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0054\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0053\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0052\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0051\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0050\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0049\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0049\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0048\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0050\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0050\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.1561 - val_loss: 0.0637\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0324\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0418 - val_loss: 0.0211\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0315 - val_loss: 0.0151\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0254 - val_loss: 0.0122\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0100\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0088\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0081\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0166 - val_loss: 0.0076\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0075\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0074\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0074\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0074\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0074\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0146 - val_loss: 0.0075\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0075\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0075\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0251 - val_loss: 0.0151\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0161 - val_loss: 0.0135\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0119\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0132 - val_loss: 0.0114\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0124 - val_loss: 0.0104\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0098\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0093\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0089\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0087\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0084\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0082\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0081\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0080\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0078\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0077\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0076\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0076\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0076\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0075\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0076\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0073\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0073\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0073\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0072\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0073\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0072\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0072\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0072\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0072\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0071\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0070\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0070\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0072\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0070\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0068\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0069\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0070\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0070\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0068\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0161 - val_loss: 0.0094\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0082\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0077\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0070\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0068\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0066\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0065\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0063\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0063\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0063\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0064\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0063\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0064\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0065\n",
            "layer: 2\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0240 - val_loss: 0.0151\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - val_loss: 0.0121\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0109\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - val_loss: 0.0104\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0100\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.0097\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0096\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0095\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0093\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0096\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0094\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0094\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0092\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0093\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0090\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0068 - val_loss: 0.0092\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0092\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0091\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0091\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0089\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0090\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0090\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 0.0091\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0090\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0090\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0266 - val_loss: 0.0188\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0110\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0094\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0083\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0075\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0071\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0068\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0066\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0063\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0063\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0060\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0059\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0058\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0058\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0057\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0058\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0057\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0057\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0057\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0056\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0056\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0056\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0057\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0056\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0057\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0056\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0056\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0056\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0056\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0056\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0057\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0055\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0055\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0056\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0696 - val_loss: 0.0266\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0341 - val_loss: 0.0161\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0118\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0222 - val_loss: 0.0094\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0194 - val_loss: 0.0080\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0072\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0069\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - val_loss: 0.0067\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0067\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0067\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0067\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0068\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0147 - val_loss: 0.0068\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0069\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0159 - val_loss: 0.0138\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0126\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0117\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0111\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0104\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0099\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0095\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0091\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0089\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0086\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0083\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0081\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0079\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0077\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0076\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0075\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0074\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0075\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0075\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0074\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0072\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0072\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0071\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0070\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0070\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0070\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0069\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0069\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0068\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0068\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0072\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0070\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0297 - val_loss: 0.0243\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0172\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0119\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0101\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0097\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0094\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0091\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0088\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0086\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0084\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0082\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0080\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0079\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0078\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0077\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0076\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0076\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0075\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0075\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0075\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0074\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0078 - val_loss: 0.0074\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0074\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0074\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0074\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0075\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0074\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0075\n",
            "layer: 3\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0130\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0100\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0087\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0079\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0075\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0072\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0069\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0067\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0065\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0065\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0063\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0063\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0062\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0062\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0061\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0061\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0061\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0061\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0061\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0060\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0061\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0061\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0061\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0061\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0120\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0108\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0098\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0091\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0086\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0080\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0074\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0071\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0068\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0062\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0061\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0058\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0057\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0058\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0056\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0056\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0055\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0055\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0055\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0055\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0055\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0055\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0055\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0055\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0055\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0055\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0589 - val_loss: 0.0212\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0114\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0223 - val_loss: 0.0096\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0082\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0176 - val_loss: 0.0070\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0160 - val_loss: 0.0062\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0059\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0057\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0054\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0053\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0053\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0052\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0052\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0054\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0055\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0054\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0053\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0330 - val_loss: 0.0205\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0142\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0168 - val_loss: 0.0115\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0107\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - val_loss: 0.0099\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0093\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0090\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0087\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0084\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0079\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0076\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0076\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0073\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0071\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0069\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0069\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0067\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0068\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0068\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0117 - val_loss: 0.0075\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0071\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0070\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0069\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0068\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0068\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0068\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0068\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "layer: 4\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0151 - val_loss: 0.0077\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0068\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0067\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0064\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0063\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0063\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0063\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0061\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0061\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0075 - val_loss: 0.0062\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0062\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0061\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0062\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0062\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0063\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0064\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0064\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0294 - val_loss: 0.0181\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0137\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0122\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0109\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0097\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0090\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0084\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0081\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0080\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0072\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0072\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0067\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0065\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0065\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0061\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0061\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0058\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0058\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0057\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0056\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0054\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0053\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0052\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0051\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0050\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0050\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0050\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0050\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0049\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0048\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0048\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0048\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0049\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0053 - val_loss: 0.0049\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0048\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0048\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0047\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0049\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0048\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0048\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0048\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0048\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0067\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0059\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0054\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0052\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0050\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0050\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0048\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0048\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0048\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0048\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0049\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0049\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0051\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0050\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0052\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0340 - val_loss: 0.0152\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0093\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0086\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0083\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0081\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0077\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0076\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0076\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0075\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0074\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0073\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0072\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0071\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0071\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0071\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0071\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0071\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0069\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0069\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0067\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0066\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0067\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0067\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0066\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0067\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0066\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0066\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0066\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0068\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0068\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0470 - val_loss: 0.0289\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0176\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0136\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0118\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0111\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0107\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0103\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0099\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0098\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0094\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0092\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0089\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0088\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0086\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0084\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0083\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0082\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0081\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0080\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0078\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0078\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0077\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0076\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0075\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0076\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0075\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0075\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0075\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0075\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0074\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0074\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0074\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0074\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0074\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0073\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0073\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0074\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0074\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0074\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0073\n",
            "layer: 5\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0643 - val_loss: 0.0284\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0195\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0158 - val_loss: 0.0174\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - val_loss: 0.0161\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0148\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0139\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0133\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0127\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0122\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0117\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0114\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0110\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0109\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0101\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0100\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0095\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0091\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0090\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0089\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0089\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0086\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0085\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0082\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0082\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0081\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0080\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0081\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0078\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0079\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0076\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0080\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0077\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0075\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0076\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0076\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0074\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0077\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0075\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0075\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0076\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0075\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0213 - val_loss: 0.0139\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0112\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0097\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0082\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0080\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0076\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0074\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0070\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0070\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0069\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0066\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0065\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0067\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0065\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0065\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0063\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0064\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0064\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0064\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0064\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0064\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0202 - val_loss: 0.0061\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0055\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0051\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0050\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0049\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0051\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0050\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0051\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0051\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0052\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0284 - val_loss: 0.0164\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - val_loss: 0.0118\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0106\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0101\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0095\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0091\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0089\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0086\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0084\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0082\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0080\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0078\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0076\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0074\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0073\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0072\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0072\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0069\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0068\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0066\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0066\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0064\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0064\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0064\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0063\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0062\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0062\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0064\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0063\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0061\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0061\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0063\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0062\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0060\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0061\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0060\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0062\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0060\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0060\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0230 - val_loss: 0.0126\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0092\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0087\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0083\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0080\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0077\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0076\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0075\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0074\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0074\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0073\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0072\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0071\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0072\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0070\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0070\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0070\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0070\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0069\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0069\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0069\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0069\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0069\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0069\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0069\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0069\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0069\n",
            "layer: 6\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0152 - val_loss: 0.0131\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0112\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0108\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0104\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0102\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0099\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0100\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0099\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0098\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0100\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0097\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0098\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0097\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0103\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0104\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0107\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0154 - val_loss: 0.0098\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0092\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0089\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0084\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0071 - val_loss: 0.0080\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0078\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0074\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0073\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0071\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0071\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0072\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0069\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0070\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0069\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0069\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0067\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0067\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0065\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0065\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0065\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0065\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0065\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0064\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0064\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0064\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0064\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0063\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0063\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0065\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0064\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0063\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0063\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0045 - val_loss: 0.0064\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0067\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0064\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0065\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0253 - val_loss: 0.0060\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0055\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0054\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0052\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0051\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0050\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0049\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0049\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0048\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0048\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0048\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0048\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0049\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0049\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0051\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0283 - val_loss: 0.0172\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0118\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0104\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0101\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0097\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0093\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0090\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0086\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0081\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0075\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0072\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0072\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0073\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0074\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0080\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0074\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0076\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0164 - val_loss: 0.0125\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0095\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0089\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0082\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0079\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0078\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0075\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0073\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0073\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0071\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0072\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0069\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0070\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0069\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0068\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0068\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0068\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0068\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0067\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0067\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0067\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0067\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0067\n",
            "layer: 7\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0181 - val_loss: 0.0097\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0093\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0087\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0083\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0080\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0077\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0075\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0072\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0069\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0069\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0066\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0065\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0063\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0064\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0063\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0063\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0062\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0062\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0063\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0064\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0064\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0064\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0301 - val_loss: 0.0168\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0092\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0083\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0078\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0074\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0066\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0064\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0063\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0063\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0061\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0060\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0059\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0060\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0059\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0059\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0058\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0058\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0058\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0058\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0058\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0058\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0393 - val_loss: 0.0120\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0075\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0139 - val_loss: 0.0072\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0069\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0066\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0063\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0061\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0058\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0056\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0055\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0052\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0051\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0049\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0048\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0048\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0047\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0046\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0046\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0046\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0046\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0045\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0045\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0046\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0045\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0045\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0046\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0045\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0045\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0045\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0045\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0045\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0045\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0045\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0047\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0045\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0045\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 38ms/step - loss: 0.0287 - val_loss: 0.0104\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0098\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0091\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0083\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0080\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0078\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0073\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0072\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0071\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0072\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0072\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0068\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0070\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0071\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0094\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0086\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0082\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0080\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0078\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0078\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0078\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0077\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0077\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0078\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0078\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0080\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0077\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0076\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0077\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0077\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0080\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0076\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0080\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0077\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0076\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0076\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0076\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0078\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0076\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0077\n",
            "layer: 8\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0293 - val_loss: 0.0150\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0101\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0095\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0092\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0090\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0089\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0088\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0087\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0087\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0087\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0086\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0087\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0087\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0087\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0087\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0087\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0211 - val_loss: 0.0133\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0112\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0102\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0093\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0086\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0073\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0070\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0064\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0063\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0060\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0057\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0057\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0055\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0054\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0053\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0053\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0051\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0051\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0050\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0050\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0050\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0050\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0049\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0050\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0051\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0049\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0049\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0050\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0048\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0048\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0048\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0048\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0049\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0052\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0049\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0309 - val_loss: 0.0115\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0165 - val_loss: 0.0054\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0050\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0048\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0045\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0045\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0044\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0043\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0043\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0043\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0044\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0044\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0045\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0354 - val_loss: 0.0238\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0166\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0134\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0126\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0150 - val_loss: 0.0116\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0101\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0093\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0087\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0083\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0079\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0076\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0076\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0074\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0072\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0072\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0073\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0072\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0072\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0073\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0072\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0069\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0071\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0070\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0069\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0071\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0068\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0067\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0066\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0073\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0064\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0071\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0066\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0133 - val_loss: 0.0097\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0090\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0089\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0088\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0087\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0086\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0088\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0085\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0086\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0085\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0086\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0084\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0087\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0084\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0083\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0084\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0085\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0085\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0082\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0086\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0084\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0082\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0081\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0082\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0086\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0082\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0083\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0081\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0081\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0081\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0080\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0083\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0083\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0081\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0082\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0079\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0085\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0081\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0081\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0082\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0083\n",
            "layer: 9\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0268 - val_loss: 0.0084\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0089\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0082\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0082\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0082\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0085\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0087\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0087\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0180 - val_loss: 0.0115\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0081\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0068\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0067\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0063\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0061\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0061\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0058\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0061\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0056\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0058\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0056\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0057\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0057\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0056\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0055\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0055\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0056\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0056\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0122 - val_loss: 0.0059\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0053\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0049\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0049\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0048\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0051\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0049\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0051\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0051\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0051\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0119 - val_loss: 0.0084\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0080\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0076\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0076\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0073\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0072\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0071\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0070\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0070\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0068\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0068\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0068\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0068\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0066\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0066\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0066\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0067\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0066\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0162\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0133\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0112\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0098\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0092\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0093\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0088\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0086\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0085\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0084\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0083\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0083\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0082\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0083\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0082\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0083\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0083\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0083\n",
            "layer: 10\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0157 - val_loss: 0.0096\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0084\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0080\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0079\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0077\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0077\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0078\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0075\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0075\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0073\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0073\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0072\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0074\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0073\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0077\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0077\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0076\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0445 - val_loss: 0.0164\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0111\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0098\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0091\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0087\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0084\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0082\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0080\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0078\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0076\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0075\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0074\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0073\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0072\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0071\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0072\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0072\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0072\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0072\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0072\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0047\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0051\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0046\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0047\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0045\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0047\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0046\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0048\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0047\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0047\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0234 - val_loss: 0.0116\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - val_loss: 0.0106\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0098\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0092\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0087\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0084\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0082\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0078\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0076\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0074\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0072\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0072\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0070\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0068\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0067\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0066\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0066\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0063\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0064\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0062\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0061\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0063\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0060\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0059\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0059\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0057\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0059\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0060\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0058\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0056\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0057\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0059\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0059\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0058\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0059\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0829 - val_loss: 0.0400\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0372 - val_loss: 0.0249\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0237 - val_loss: 0.0184\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - val_loss: 0.0152\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0139\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0135 - val_loss: 0.0134\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0128 - val_loss: 0.0130\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - val_loss: 0.0126\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0122\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0119\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0115\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0111\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0108\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0104\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0101\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0097\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0094\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0092\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0089\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0087\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0086\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0084\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0082\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0080\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0079\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0077\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0076\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0076\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0075\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0074\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0074\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0074\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0073\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0072\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0072\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0073\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0073\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0073\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0073\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0073\n",
            "layer: 11\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0229 - val_loss: 0.0111\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0098\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0090\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0085\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0082\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0081\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0080\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0079\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0079\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0079\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0079\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0078\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0078\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0078\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0077\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0077\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0076\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0077\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0076\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0077\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0077\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0077\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0077\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0077\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0425 - val_loss: 0.0143\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0107\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0095\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0083\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0077\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0073\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0070\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0066\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0064\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0062\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0061\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0060\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0060\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0059\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0059\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0059\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0058\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0058\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0057\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0057\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0057\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0057\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0057\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0057\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0056\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0059\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0057\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0055\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0056\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0057\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0057\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0057\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0058\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0316 - val_loss: 0.0079\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0153 - val_loss: 0.0061\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0058\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0053\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0051\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0052\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0049\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0050\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0050\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0050\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0051\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0051\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0194 - val_loss: 0.0105\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0092\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0082\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0080\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0076\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0073\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0072\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0068\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0067\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0066\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0064\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0064\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0065\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0062\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0061\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0062\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0064\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0070\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0070\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0218 - val_loss: 0.0124\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0092\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0088\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0083\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0081\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0077\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0074\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0072\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0070\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0069\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0068\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0068\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0065\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0066\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0066\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0066\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0069\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0066\n",
            "layer: 12\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0173 - val_loss: 0.0116\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0101\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0091\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0084\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0079\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0074\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0072\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0068\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0067\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0066\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0065\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0063\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0062\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0061\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0061\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0061\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0061\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0061\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0061\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0061\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0062\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0105 - val_loss: 0.0072\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0069\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0068\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0067\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0066\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0065\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0063\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0062\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0060\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0059\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0063\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0060\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0056\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0061\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0059\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0058\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0057\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0057\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0145 - val_loss: 0.0077\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0060\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0058\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0056\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0053\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0054\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0051\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0053\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0052\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0050\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0052\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0050\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0054\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0052\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0050\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0272 - val_loss: 0.0114\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0118 - val_loss: 0.0094\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0088\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0085\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0083\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0081\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0078\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0077\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0076\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0075\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0074\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0074\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0073\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0073\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0072\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0069\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0068\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0065\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0063\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0064\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0063\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0063\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0062\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0063\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0061\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0060\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0060\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0061\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0062\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0063\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0061\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0059\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0059\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0059\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0058\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0057\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0057\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0056\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0057\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0058\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0057\n",
            "Epoch 52/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0057\n",
            "Epoch 53/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0055\n",
            "Epoch 54/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0055\n",
            "Epoch 55/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0055\n",
            "Epoch 56/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0056\n",
            "Epoch 57/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0055\n",
            "Epoch 58/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0055\n",
            "Epoch 59/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0055\n",
            "Epoch 60/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0060 - val_loss: 0.0056\n",
            "Epoch 61/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0055\n",
            "Epoch 62/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0056\n",
            "Epoch 63/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0055\n",
            "Epoch 64/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0055\n",
            "Epoch 65/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0055\n",
            "Epoch 66/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0055\n",
            "Epoch 67/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0054\n",
            "Epoch 68/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0055\n",
            "Epoch 69/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0055\n",
            "Epoch 70/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0055\n",
            "Epoch 71/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0059\n",
            "Epoch 72/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0056\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0168 - val_loss: 0.0105\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0101\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0097\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0093\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0090\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0089\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0087\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0086\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0085\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0084\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0084\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0084\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0084\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0084\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0081\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0081\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0081\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0080\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0080\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0079\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0081\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0078\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0077\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0077\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0077\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0076\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0075\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0075\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0075\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0074\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0075\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0076\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0074\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0075\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0075\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0073\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0074\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0074\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0073\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0073\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0075\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0074\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0073\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0073\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0073\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0071\n",
            "Epoch 47/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0072\n",
            "Epoch 48/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0074\n",
            "Epoch 49/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0072\n",
            "Epoch 50/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0072\n",
            "Epoch 51/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0072\n",
            "layer: 13\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 22ms/step - loss: 0.0119 - val_loss: 0.0092\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0084\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0083\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0083\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0082\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0082\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0082\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0081\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0080\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0080\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0079\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0079\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0078\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0079\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0078\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0078\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0078\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0078\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0077\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0077\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0079\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0077\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0077\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0077\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0076\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0076\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0077\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0077\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0076\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0078\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0114\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0092\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0082\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0078\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0073\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0072\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0069\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0068\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0066\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0065\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0066\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0063\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0063\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0062\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0062\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0061\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0061\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0061\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0061\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0061\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0060\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0061\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0061\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0179 - val_loss: 0.0058\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0045\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0046\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0045\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0044\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0045\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0044\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0045\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0044\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0044\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0045\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0045\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0235 - val_loss: 0.0087\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - val_loss: 0.0084\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0081\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0085\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0083\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0082\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0081\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0078\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0078\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0076\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0074\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0074\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0073\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0072\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0070\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0070\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0069\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0069\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0074\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0070\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0067\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0068\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0067\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0067\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0066\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0067\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0066\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0170 - val_loss: 0.0099\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0090\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0084\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0080\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0078\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0075\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0073\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0071\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0070\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0069\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0069\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0069\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0069\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0069\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0070\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0069\n",
            "layer: 14\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0308 - val_loss: 0.0133\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0100\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0090\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0089\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0084\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0076\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0074\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0072\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0070\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0069\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0069\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0069\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0112 - val_loss: 0.0092\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0080\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0076\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0076\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0071\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0074\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0062 - val_loss: 0.0068\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0068\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0067\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0066\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0070\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0063\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0065\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0063\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0063\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0062\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0062\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0061\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0061\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0061\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0061\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0059\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0060\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0060\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0061\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0060\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0060\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0540 - val_loss: 0.0114\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0214 - val_loss: 0.0066\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0065\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0142 - val_loss: 0.0058\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0130 - val_loss: 0.0055\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0053\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0051\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0050\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0049\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0048\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0048\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0095 - val_loss: 0.0048\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0048\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0048\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0049\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0047\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0047\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0047\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0046\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0047\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0046\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0046\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0048\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0046\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0046\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0048\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0239 - val_loss: 0.0159\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0140\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0122\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0112\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0105\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0094\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0086\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0079\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0076\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0071\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0068\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0066\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0064\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0063\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0062\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0060\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0059\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0059\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0058\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0058\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0056\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0057\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0056\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0056\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0056\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0057\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0055\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0057\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0056\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0055\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0057\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0055\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0058\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0060\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0057\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0056\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0058\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0118 - val_loss: 0.0094\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0091\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0086\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0077\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0075\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0073\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0071\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0074\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0071\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0071\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0073\n",
            "layer: 15\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0103 - val_loss: 0.0098\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0093\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0087\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0085\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0083\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0083\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0083\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0081\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0080\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0080\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0079\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0079\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0078\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0080\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0078\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0080\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0079\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0078\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0078\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0077\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0078\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0078\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0080\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0078\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0079\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0167 - val_loss: 0.0112\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0098\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0084\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0080\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0075\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0065\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0065\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0070\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0063\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0066\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0061\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0067\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0061\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0063\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0061\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0061\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0172 - val_loss: 0.0056\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0052\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0052\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0051\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0051\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0053\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0050\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0052\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0051\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0050\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0052\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0051\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0052\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0051\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0052\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0187 - val_loss: 0.0128\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0093\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0082\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0078\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0078\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0077\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0075\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0075\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0076 - val_loss: 0.0072\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0071\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0074\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0070\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0071\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0071\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0072\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0072\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0237 - val_loss: 0.0126\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0096\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0094\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0090\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0091\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0091\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0088\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0088\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0088\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0087\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0086\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0086\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0088\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0084\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0085\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0087\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0085\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0085\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0084\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0087\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0084\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0084\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0086\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0083\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0083\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0082\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0082\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0081\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0081\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0083\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0081\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0082\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0079\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0081\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0083\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0080\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0080\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0080\n",
            "layer: 16\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0238 - val_loss: 0.0112\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0103\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0092\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0083\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0077\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0074\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0074\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0073\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0072\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0071\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0071\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0070\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0070\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0070\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0070\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0070\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0069\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0070\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0068\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0067\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0067\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0067\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0066\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0067\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0066\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0067\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0085\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0075\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0071\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0071\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0070\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0069\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0068\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0067\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0066\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0066\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0064\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0064\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0064\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0062\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0062\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0061\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0061\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0060\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0060\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0060\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0060\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0061\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0060\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0061\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0060\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0061\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0060\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0058\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0060\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0061\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0254 - val_loss: 0.0064\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0058\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0054\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0052\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0050\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0050\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0050\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0050\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0049\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0048\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0049\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0048\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0049\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0049\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0049\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0192 - val_loss: 0.0142\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0110\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0091\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0088\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0080\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0075\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0075\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0072\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0070\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0067\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0084 - val_loss: 0.0067\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0065\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0065\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0064\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0064\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0063\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0063\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0066\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0064\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0063\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0062\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0063\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0061\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0062\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0063\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0063\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0062\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0062\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0169 - val_loss: 0.0081\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0075\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0073\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0069\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0066\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0067\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0066\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0065\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0078 - val_loss: 0.0065\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0065\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0070\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0067\n",
            "layer: 17\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0712 - val_loss: 0.0190\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0219 - val_loss: 0.0146\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0112\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - val_loss: 0.0099\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0091\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0088\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0084\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0082\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0081\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0082\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0082\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0081\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0081\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0080\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0071 - val_loss: 0.0080\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0080\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0080\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0079\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0079\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0080\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0080\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0080\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0079\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0079\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0078\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0078\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0080\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0079\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0079\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0081\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0117 - val_loss: 0.0108\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0098\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0091\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0074 - val_loss: 0.0086\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0081\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0078\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0075\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0071\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0070\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0069\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0070\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0066\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0066\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0068\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0064\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0065\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0064\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0064\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0063\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0063\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0063\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0063\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0061\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0064\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0062\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0063\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0062\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0062\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0058\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0051\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0051\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0053\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0050\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0054\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0051\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0054\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0054\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0052\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0182 - val_loss: 0.0103\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0097\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.0091\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0102 - val_loss: 0.0087\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0083\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0080\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0077\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0075\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0073\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0069\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0069\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0069\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0066\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0064\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0063\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0068\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0069\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0063\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0062\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0062\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0062\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0063\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0061\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0064\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0061\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0061\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0063\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0061\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0060\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0067\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0063\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0060\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0062\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0068\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0063\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0063\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0062\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0190 - val_loss: 0.0089\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0082\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0079\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0075\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0073\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0073\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0073\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0072\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0073\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0072\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0075\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0075\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0076\n",
            "layer: 18\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0102 - val_loss: 0.0090\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0086\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0081\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0083\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0079\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0078\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0077\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0074\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0074\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0074\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0075\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0074\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0074\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0073\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0074\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0073\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0073\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0072\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0073\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0074\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0074\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0073\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0074\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0127\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0108\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0098\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0089\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0081\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0075\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0074\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0070\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0070\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0076\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0070\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0073\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0070\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0071\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0066\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0068\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0066\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0067\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0065\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0066\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0065\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0065\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0065\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0064\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0063\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0063\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0064\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0064\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0063\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0063\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0062\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0063\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0063\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0067\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0064\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0063\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 9ms/step - loss: 0.0169 - val_loss: 0.0054\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0051\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0050\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0051\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0048\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0050\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0047\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0049\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0050\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0050\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0052\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0051\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0081\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0076\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0074\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0074\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0072\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0071\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0070\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0069\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0069\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0068\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0067\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0067\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0066\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0065\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0065\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0077 - val_loss: 0.0065\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0062\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0061\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0060\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0060\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0060\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0059\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0061\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0059\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0059\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0058\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0058\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0059\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0063\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0064 - val_loss: 0.0058\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0056\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0058\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0060\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0059\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0058\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 8ms/step - loss: 0.0264 - val_loss: 0.0146\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0100\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0091\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0086\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0081\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0077\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0073\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0070\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0069\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0068\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0066\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0065\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0066\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0075 - val_loss: 0.0064\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0065\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0067\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0067\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0065\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0065\n",
            "layer: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "oJ3NG-ME5shn",
        "outputId": "b7e27496-5a0e-42a7-cddd-5c859d99712a"
      },
      "source": [
        "# plot\n",
        "n = np.arange(0,max_layer)\n",
        "plt.plot(n,y_arr,c = 'red', label ='test error') \n",
        "\n",
        "plt.plot(n,x_arr,c = 'blue', label = 'train error')\n",
        "plt.xlabel('numer of layers')\n",
        "plt.ylabel('loss')\n",
        "plt.title('train error vs test error in 9~18 data')\n",
        "plt.savefig('train error vs test error in 9~18')\n",
        "plt.legend()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f72f5fb8150>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDAMEzaLVmjo",
        "outputId": "f92a1191-95a9-4346-d016-5ffd05f04703"
      },
      "source": [
        "#\n",
        "for train, test in skf.split(x,y_cat): \n",
        "  model = Sequential()\n",
        "  model.add(Dense(15,input_dim = 15, activation= 'relu'))\n",
        "  model.add(Dense(5,activation = 'relu'))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss = 'mean_squared_error', optimizer = 'adam') \n",
        "  model.fit(x[train],y[train], validation_split= 0.2, epochs = 300, batch_size= 10, callbacks = [ESC])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0326 - val_loss: 0.0226\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0230 - val_loss: 0.0164\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0168 - val_loss: 0.0123\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0129 - val_loss: 0.0103\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0109 - val_loss: 0.0097\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0095\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0092\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0090\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0087\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0085\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0083\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0081\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0084 - val_loss: 0.0079\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0077\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0080 - val_loss: 0.0076\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0075\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0074\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0073\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0076 - val_loss: 0.0072\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0071\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0070\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0073 - val_loss: 0.0070\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0069\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0069\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 0.0068\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0068\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0068\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0067\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0067\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0067\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0067\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0067\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0064 - val_loss: 0.0067\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0067\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0066\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0067\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0068\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0067\n",
            "Epoch 45/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0067\n",
            "Epoch 46/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0061 - val_loss: 0.0068\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.1173 - val_loss: 0.0542\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0299\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0220\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0206 - val_loss: 0.0184\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0159\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.0144\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0134\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - val_loss: 0.0127\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0123\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - val_loss: 0.0120\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0118\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0118\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0117\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0117\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0116\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0116\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0931 - val_loss: 0.0284\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0450 - val_loss: 0.0178\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0129\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0103\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0207 - val_loss: 0.0087\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0185 - val_loss: 0.0079\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0074\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - val_loss: 0.0072\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0071\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0153 - val_loss: 0.0070\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0150 - val_loss: 0.0070\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0071\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0147 - val_loss: 0.0071\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0071\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0146 - val_loss: 0.0072\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 7ms/step - loss: 0.0192 - val_loss: 0.0096\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0084\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0079\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - val_loss: 0.0078\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0075\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0073\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0070\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0072\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0070\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0068\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0068\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0067\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0067\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0066\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - val_loss: 0.0065\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0065\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0064\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0062\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0062\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0062\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0062\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0062\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0062\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0061\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0062\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0060\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0074 - val_loss: 0.0061\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0062\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0061\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0061\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0061\n",
            "Epoch 1/300\n",
            "28/28 [==============================] - 1s 6ms/step - loss: 0.0347 - val_loss: 0.0218\n",
            "Epoch 2/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0136\n",
            "Epoch 3/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0152 - val_loss: 0.0123\n",
            "Epoch 4/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0117\n",
            "Epoch 5/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0124 - val_loss: 0.0112\n",
            "Epoch 6/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0109\n",
            "Epoch 7/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0105\n",
            "Epoch 8/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0105 - val_loss: 0.0101\n",
            "Epoch 9/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0097\n",
            "Epoch 10/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0094\n",
            "Epoch 11/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0091\n",
            "Epoch 12/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0089\n",
            "Epoch 13/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0086\n",
            "Epoch 14/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0084\n",
            "Epoch 15/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0082\n",
            "Epoch 16/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0079\n",
            "Epoch 17/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0078\n",
            "Epoch 18/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0076\n",
            "Epoch 19/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - val_loss: 0.0075\n",
            "Epoch 20/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0074\n",
            "Epoch 21/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0073\n",
            "Epoch 22/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0071\n",
            "Epoch 23/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0071\n",
            "Epoch 24/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0070\n",
            "Epoch 25/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 26/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0069\n",
            "Epoch 27/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0068\n",
            "Epoch 28/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 29/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0067\n",
            "Epoch 30/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0066\n",
            "Epoch 31/300\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 32/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 33/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0067\n",
            "Epoch 34/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0065\n",
            "Epoch 35/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 36/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0065\n",
            "Epoch 37/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 38/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0066\n",
            "Epoch 39/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 40/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0064\n",
            "Epoch 41/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0065\n",
            "Epoch 42/300\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.0065 - val_loss: 0.0066\n",
            "Epoch 43/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0066\n",
            "Epoch 44/300\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HsHRJIxfVmnE",
        "outputId": "4f05beb0-c4a9-4776-a3c9-ad9efd3f6e48"
      },
      "source": [
        "# plot\n",
        "\n",
        "# about last fold\n",
        "# y_predict = model.predict(x[test])\n",
        "\n",
        "# about all data\n",
        "y_predict = model.predict(x) \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# about last fold\n",
        "# plt.scatter(y[test], y_predict, alpha=0.4)\n",
        "\n",
        "# about all data\n",
        "plt.scatter(y, y_predict, alpha=0.4)\n",
        "\n",
        "plt.plot([0,1],[0,1], c = 'red')\n",
        "plt.xlabel(\"Actual population\")\n",
        "plt.ylabel(\"Predicted population\")\n",
        "plt.title(\"Deep Neural Network dense 5 in 9~18data\")\n",
        "plt.savefig('DNN_test_9~18.png')\n",
        "plt.show() "
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNrAEHm3h0up",
        "outputId": "a1b51b3d-c224-4ad7-e9f7-0ed374102a01"
      },
      "source": [
        "list_y = y.tolist()\n",
        "list_predicty = []\n",
        "\n",
        "for i in range(len(list_y)):\n",
        "    list_predicty.append(y_predict[i].item())\n",
        "diff = []\n",
        "for i in range(len(list_y)):\n",
        "    diff.append(list_y[i] - list_predicty[i])\n",
        "diff"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.025427261387767103,\n",
              " 0.015011827638151926,\n",
              " 0.09854896910062222,\n",
              " -0.19763365622241869,\n",
              " -0.0030823200661181938,\n",
              " 0.03190299296161131,\n",
              " -0.029386641194092233,\n",
              " -0.05461767241395423,\n",
              " -0.07766011513046063,\n",
              " 0.05319204924353285,\n",
              " -0.006664072882143296,\n",
              " 0.05674409369903785,\n",
              " 0.06193246865267055,\n",
              " 0.04537145482306715,\n",
              " -0.04519044384733473,\n",
              " -0.05795901245078215,\n",
              " 0.03296877052253391,\n",
              " -0.06114655392039196,\n",
              " -0.054952064686465456,\n",
              " -0.19400756865393318,\n",
              " -0.040165065402969824,\n",
              " -0.03819148965482967,\n",
              " -0.08896184179378311,\n",
              " -0.13329519802976011,\n",
              " 0.05930355216227498,\n",
              " 0.04978774438866462,\n",
              " -0.06294721632002293,\n",
              " -0.05477068214397221,\n",
              " 0.036837915055922515,\n",
              " 0.04097708344454554,\n",
              " -0.11757445459147167,\n",
              " -0.009205571650971661,\n",
              " 0.07140087276354229,\n",
              " 0.04622973825808363,\n",
              " -0.08463762170003503,\n",
              " -0.024147093814410076,\n",
              " 0.010040831571685366,\n",
              " 0.051719791561615075,\n",
              " 0.008971304544065903,\n",
              " -0.07204776057254028,\n",
              " 0.01828470454736504,\n",
              " -0.0699585074578752,\n",
              " -0.08864763515435456,\n",
              " -0.05988304173847657,\n",
              " 0.0771895030815401,\n",
              " -0.00923362385733284,\n",
              " -0.028909501867542292,\n",
              " 0.007737044153687284,\n",
              " -0.028781655298390205,\n",
              " -0.0643177142073477,\n",
              " -0.09481674803452327,\n",
              " -0.07334182861085115,\n",
              " -0.004909026438560241,\n",
              " -0.05986052913795864,\n",
              " -0.12412144432507427,\n",
              " 0.10114628035344958,\n",
              " -0.01800227444595083,\n",
              " -0.012612734553578364,\n",
              " 0.11288386399528272,\n",
              " 0.18147220892101684,\n",
              " -0.03453770455040579,\n",
              " -0.02971313772284942,\n",
              " -0.04259382850788447,\n",
              " -0.05515191832826345,\n",
              " -0.003915653515317807,\n",
              " 0.086577915612358,\n",
              " -0.033727591904087764,\n",
              " 0.032972798009821544,\n",
              " 0.05296401561873795,\n",
              " 0.06161108192758208,\n",
              " 0.10263090831340183,\n",
              " 0.01712004561343465,\n",
              " 0.13065055067976933,\n",
              " 0.11772302666440349,\n",
              " 0.10946581341619838,\n",
              " 0.01803828221221848,\n",
              " 0.0103164264468317,\n",
              " -0.015121740734084843,\n",
              " -0.05359087650161718,\n",
              " -0.01904788902000165,\n",
              " 0.006955159536602515,\n",
              " -0.0276550411425482,\n",
              " 0.0007796066588399431,\n",
              " 0.012801911220452114,\n",
              " 0.03245606057130149,\n",
              " -0.024233612025818196,\n",
              " -0.10915492078562394,\n",
              " -0.1369126215786788,\n",
              " 0.023245909433131012,\n",
              " -0.08011107196307243,\n",
              " -0.08881101817328879,\n",
              " 0.019667386864868075,\n",
              " -0.07089555255027,\n",
              " -0.08565751477962358,\n",
              " 0.05161658410430353,\n",
              " -0.09156499882935362,\n",
              " -0.09232697238357146,\n",
              " -0.042682646781277825,\n",
              " -0.0036679413394095986,\n",
              " 0.053992927942570934,\n",
              " -0.020179605779576615,\n",
              " 0.013124781277515277,\n",
              " -0.036432344059529526,\n",
              " -0.053441839044882575,\n",
              " -0.04325689516592526,\n",
              " -0.0767657699031731,\n",
              " -0.03255853584331875,\n",
              " 0.08086314947413162,\n",
              " -0.02560720434246605,\n",
              " 0.01846850978014078,\n",
              " -0.044160492924036246,\n",
              " 0.10323205861912788,\n",
              " -0.033461775145747205,\n",
              " -0.020192214034327166,\n",
              " -0.0319595212599305,\n",
              " -0.08052429856668081,\n",
              " -0.12956358154762884,\n",
              " -0.15027372850691206,\n",
              " -0.030266947842774047,\n",
              " -0.021114428367481952,\n",
              " -0.01923692739810144,\n",
              " 0.06505177034731402,\n",
              " -0.04966832854869942,\n",
              " -0.037574880775012226,\n",
              " -0.06609652003398342,\n",
              " -0.12303526467502006,\n",
              " 0.02204536709873725,\n",
              " 0.10531258015071016,\n",
              " -0.06547840846945724,\n",
              " -0.06377009869896896,\n",
              " 0.004956979301645792,\n",
              " -0.029678612438219176,\n",
              " -0.0692149042065931,\n",
              " -0.029966638818283625,\n",
              " -0.050364312625516425,\n",
              " -0.02853468670031123,\n",
              " 0.08547049390214786,\n",
              " 0.001386316078351324,\n",
              " -0.00557935343930218,\n",
              " -0.08114667188282054,\n",
              " -0.04726777953383851,\n",
              " -0.04139373303972166,\n",
              " -0.0034200591867989266,\n",
              " 0.002670912754581811,\n",
              " -0.08072776170967022,\n",
              " -0.05721346870646378,\n",
              " -0.10510723434210881,\n",
              " -0.07590168538591036,\n",
              " -0.03768301654708073,\n",
              " -0.03918277054167671,\n",
              " -0.08562846890348925,\n",
              " 0.035039480214118485,\n",
              " 0.15699542221496582,\n",
              " 0.04162076813744059,\n",
              " 0.020296163549189047,\n",
              " -0.05648885960196323,\n",
              " 0.004612728318969195,\n",
              " 0.08531334309194175,\n",
              " -0.06238603843805382,\n",
              " -0.05542148584445636,\n",
              " -0.10184510358252602,\n",
              " -0.03373823102459461,\n",
              " -0.07875885606321734,\n",
              " -0.029516088112382682,\n",
              " 0.06988796692007287,\n",
              " 0.02640830494978652,\n",
              " -0.012066921803657982,\n",
              " -0.006668700034002245,\n",
              " 0.04835918852269663,\n",
              " -0.05034818474793551,\n",
              " -0.003902164563532609,\n",
              " 0.05410689722289155,\n",
              " 0.01252258428061187,\n",
              " -0.017780677373306145,\n",
              " -0.027063619539191452,\n",
              " 0.08829390773307727,\n",
              " -0.008887553262960021,\n",
              " 0.0037372833638296687,\n",
              " 0.06784446043847572,\n",
              " -0.007932642600732162,\n",
              " -0.004564763977098749,\n",
              " -0.020728737239378806,\n",
              " -0.110485705422926,\n",
              " 0.09272603303027402,\n",
              " 0.007945037766203644,\n",
              " -0.051266808111101375,\n",
              " -0.028220997940300918,\n",
              " 0.44353451981305203,\n",
              " 0.002528127544294781,\n",
              " -0.048321468404643325,\n",
              " 0.01261295884112186,\n",
              " 0.11014972042416807,\n",
              " 0.15141819678550178,\n",
              " 0.27669458792257373,\n",
              " -0.021818598302904613,\n",
              " -0.0027655089920059217,\n",
              " 0.10550743999292309,\n",
              " -0.018059072677494153,\n",
              " 0.011923367322462602,\n",
              " 0.039504080923027096,\n",
              " 0.0031961391612312373,\n",
              " -0.030606889933717574,\n",
              " -0.05433470057906198,\n",
              " -0.09781525496841056,\n",
              " -0.03784081423584962,\n",
              " 0.0037823634250551685,\n",
              " 0.024061919660540554,\n",
              " -0.02308062527948225,\n",
              " -0.011229780979147008,\n",
              " -0.011676013566152221,\n",
              " -0.0474738040846623,\n",
              " 0.07165279785702927,\n",
              " 0.008317657521112382,\n",
              " 0.07014057521172351,\n",
              " -0.010891165328850774,\n",
              " 0.029807392030452726,\n",
              " -0.054641887028056564,\n",
              " -0.0363027226349735,\n",
              " -0.024382125539666816,\n",
              " 0.0026546748339046494,\n",
              " 0.07288993040264546,\n",
              " -0.07117767138071741,\n",
              " -0.024441092576771267,\n",
              " 0.01353084425679818,\n",
              " -0.016325226175758427,\n",
              " -0.04499462890738931,\n",
              " -0.028537107635196263,\n",
              " -0.014411796401298964,\n",
              " 0.002126233534169214,\n",
              " -0.06916401288866614,\n",
              " -0.08586999315281006,\n",
              " -0.06638376043491721,\n",
              " 0.001876381278354905,\n",
              " -0.06951492428292771,\n",
              " 0.007561883792314289,\n",
              " -0.04521874443672513,\n",
              " -0.09766406576919798,\n",
              " -0.020757358174251117,\n",
              " -0.08343212905527057,\n",
              " 0.010015142601807858,\n",
              " -0.03313325210632698,\n",
              " -0.025634062411191205,\n",
              " -0.027501813538132358,\n",
              " -0.0333679080490378,\n",
              " 0.10410359811137404,\n",
              " -0.032681262398302144,\n",
              " -0.10096254915373847,\n",
              " -0.019714156161399113,\n",
              " -0.12802897557955767,\n",
              " -0.02259766383943089,\n",
              " 0.007966124063136584,\n",
              " -0.08078270235403093,\n",
              " -0.06658472087209191,\n",
              " -0.07985660409402255,\n",
              " 0.007748864910697678,\n",
              " -0.04129806410646976,\n",
              " -0.1130281595296305,\n",
              " -0.016739292663542626,\n",
              " 0.07385504262925247,\n",
              " -0.21795309110366795,\n",
              " -0.05540638972163825,\n",
              " 0.23244278028886534,\n",
              " -0.061921911598135565,\n",
              " 0.016514152012695973,\n",
              " -0.016254578641831413,\n",
              " -0.06430088605225132,\n",
              " -0.03858158854311336,\n",
              " 0.006551744105287499,\n",
              " 0.04887030986185678,\n",
              " -0.08245909245898084,\n",
              " -0.05418590553416337,\n",
              " 0.10091053836804675,\n",
              " -0.06252612316176959,\n",
              " 0.10299371678640229,\n",
              " -0.004544773420649906,\n",
              " -0.01702983674155714,\n",
              " 0.033221849424717204,\n",
              " 0.37229179375729127,\n",
              " 0.7013344168663025,\n",
              " 0.12779415918717818,\n",
              " 0.09682498055725952,\n",
              " -0.030623852412771616,\n",
              " 0.0442988593138928,\n",
              " -0.021636747196786703,\n",
              " -0.009029979442035763,\n",
              " 0.22405647866466655,\n",
              " -0.026467656790943178,\n",
              " 0.03390424355150373,\n",
              " -0.019468776928244613,\n",
              " 0.0902150811098611,\n",
              " -0.025709354048393612,\n",
              " 0.008664926809526102,\n",
              " -0.056529186374167116,\n",
              " -0.04009314293206634,\n",
              " -0.0828996021678996,\n",
              " -0.02785648614458941,\n",
              " -0.08102049319856523,\n",
              " -0.05293926084415296,\n",
              " 0.16874724499431643,\n",
              " 0.019978064036259874,\n",
              " 0.06302533014655459,\n",
              " -0.03698543008327673,\n",
              " -0.061858855096967855,\n",
              " -0.04896169709127246,\n",
              " -0.05730848719568321,\n",
              " 0.0033448651107557126,\n",
              " 0.02924029272436926,\n",
              " -0.03430068058690108,\n",
              " -0.06417709112523504,\n",
              " 0.029423447327130287,\n",
              " 0.0747967475072136,\n",
              " -0.0873727496948983,\n",
              " -0.027964941360778622,\n",
              " -0.0914647770613756,\n",
              " 0.021082352314849867,\n",
              " 0.010103968090177662,\n",
              " -0.044464893828706734,\n",
              " -0.014700995441988413,\n",
              " -0.07822236229312907,\n",
              " -0.05037575043974794,\n",
              " -0.047889454359487986,\n",
              " 0.08125427030818055,\n",
              " 0.05612237877233117,\n",
              " 0.005085292455141943,\n",
              " 0.0017116136272099375,\n",
              " -0.11152909530024965,\n",
              " 0.017278102463339357,\n",
              " 0.01276383903037509,\n",
              " -0.013405672409474753,\n",
              " -0.04058035840184507,\n",
              " 0.016671757910468432,\n",
              " -0.02001922308223103,\n",
              " -0.00806112582980903,\n",
              " -0.08750191491519921,\n",
              " -0.024253990240790613,\n",
              " -0.08522905210160489,\n",
              " 0.0862406394103985,\n",
              " -0.027906083182633934,\n",
              " 0.03343611789764664,\n",
              " -0.005354897033199996,\n",
              " 0.002411310848012757,\n",
              " -0.043283361929882504,\n",
              " -0.1330984838296077,\n",
              " 0.038410396423516874,\n",
              " -0.0697816526506514,\n",
              " 0.029362212986499242,\n",
              " -0.05099936563825448,\n",
              " -0.13292869427327905,\n",
              " -0.06697027169201032,\n",
              " -0.05847769402722228,\n",
              " -0.08791969856058424,\n",
              " 0.09283858166332246,\n",
              " 0.03710433053551504,\n",
              " 0.3441476179795888,\n",
              " 0.06489591524477925,\n",
              " 0.029278066798669705,\n",
              " -0.03881893635118695,\n",
              " 0.01033260264842728,\n",
              " -0.05743810692383647,\n",
              " -0.03522158871452567,\n",
              " 0.0007672231114863315,\n",
              " 0.004091424008455885,\n",
              " 0.006284551545052544,\n",
              " 0.05062493280916611,\n",
              " -0.1030404092867003,\n",
              " -0.0013816930388100002,\n",
              " -0.017620898530712692,\n",
              " 0.012812695255468881,\n",
              " -0.06289109393595729,\n",
              " -0.12499669188611634,\n",
              " 0.0252227536334573,\n",
              " 0.022416982312044725,\n",
              " -0.06633938458067752,\n",
              " -0.03184178576564084,\n",
              " -0.0022860103404242355,\n",
              " -0.05965234846736323,\n",
              " -0.05251122969109061,\n",
              " -0.11224807053804398,\n",
              " -0.05510976763405995,\n",
              " 0.07751999212688862,\n",
              " 0.12017434171693009,\n",
              " 0.047011195688249546,\n",
              " -0.07879945626607837,\n",
              " 0.10217785435883453,\n",
              " -0.031072349763835022,\n",
              " 0.09910008305950274,\n",
              " -0.09864111087372678,\n",
              " -0.004248219858965285,\n",
              " 0.049387851301274766,\n",
              " 0.1972425731864369,\n",
              " -0.010710017817992704,\n",
              " -0.06528727849895782,\n",
              " -0.09241743938677499,\n",
              " -0.03892227772793193,\n",
              " -0.012113758133562025,\n",
              " -0.030587276817167823,\n",
              " 0.0011134264882282086,\n",
              " 0.08387302591895437,\n",
              " 0.02264331425948521,\n",
              " -0.12912266222126006,\n",
              " -0.07856863182101516,\n",
              " -0.01908720497274749,\n",
              " 0.05665302485978305,\n",
              " -0.0621836720848239,\n",
              " -0.008426147905420178,\n",
              " -0.047981270975983065,\n",
              " -0.11774516073789143,\n",
              " -0.04456708708699633,\n",
              " 0.15078624858998507,\n",
              " -0.03790458853453407,\n",
              " -0.051150381619966004,\n",
              " -0.04020605978989611,\n",
              " -0.03162936303447622,\n",
              " 0.014866812365884219,\n",
              " 0.03988629336637123,\n",
              " 0.08956004767213233,\n",
              " -0.06757921241675063,\n",
              " -0.01704183493875097,\n",
              " -0.01074068903926756,\n",
              " -0.07728130551462059,\n",
              " -0.041294049906611716,\n",
              " -0.09732598036646968,\n",
              " -0.048436263462393866,\n",
              " -0.018656366433510763]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL2NZKbxvIkc"
      },
      "source": [
        "df2['diff'] = diff"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "kOIWbCUl2TVQ",
        "outputId": "442b28df-ce45-4a07-c59d-64c5770ca783"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>nfnc</th>\n",
              "      <th>nfc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>nsnc</th>\n",
              "      <th>nsc</th>\n",
              "      <th>affnc</th>\n",
              "      <th>anfnc</th>\n",
              "      <th>anfc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>ansnc</th>\n",
              "      <th>ansc</th>\n",
              "      <th>population</th>\n",
              "      <th>pop_cat</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>가락1동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.164634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.022764</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.034783</td>\n",
              "      <td>0.155581</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.025427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>가락2동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.161290</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.016260</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.056098</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.154967</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.015012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>가락본동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.146341</td>\n",
              "      <td>0.154472</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.045161</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.040244</td>\n",
              "      <td>0.040650</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.078261</td>\n",
              "      <td>0.264574</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.098549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>가리봉동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.293902</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.234783</td>\n",
              "      <td>0.062857</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.197634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>가산동</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.913043</td>\n",
              "      <td>0.335484</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.343902</td>\n",
              "      <td>0.058537</td>\n",
              "      <td>0.408</td>\n",
              "      <td>0.286957</td>\n",
              "      <td>0.636785</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.003082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dong  highway      ffnc  nfnc  ...      ansc  population  pop_cat      diff\n",
              "0  가락1동      0.0  0.225806  0.00  ...  0.034783    0.155581      2.0 -0.025427\n",
              "1  가락2동      0.0  0.161290  0.00  ...  0.130435    0.154967      2.0  0.015012\n",
              "2  가락본동      0.0  0.032258  0.00  ...  0.078261    0.264574      3.0  0.098549\n",
              "3  가리봉동      0.0  0.032258  0.05  ...  0.234783    0.062857      1.0 -0.197634\n",
              "4   가산동      0.0  1.000000  0.20  ...  0.286957    0.636785      5.0 -0.003082\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdswqfmk2TZ3"
      },
      "source": [
        "a = df1['diff'].sort_values()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_z2YVAtwC7v"
      },
      "source": [
        "df2_sort = df2.sort_values(by = df2.columns[-1], ascending= False )"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "j_zeaYq2yCbG",
        "outputId": "7b8324e2-022d-4181-f663-dc96328aca80"
      },
      "source": [
        "df2_sort"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dong</th>\n",
              "      <th>highway</th>\n",
              "      <th>ffnc</th>\n",
              "      <th>nfnc</th>\n",
              "      <th>nfc</th>\n",
              "      <th>fsnc</th>\n",
              "      <th>fsc</th>\n",
              "      <th>nsnc</th>\n",
              "      <th>nsc</th>\n",
              "      <th>affnc</th>\n",
              "      <th>anfnc</th>\n",
              "      <th>anfc</th>\n",
              "      <th>afsnc</th>\n",
              "      <th>afsc</th>\n",
              "      <th>ansnc</th>\n",
              "      <th>ansc</th>\n",
              "      <th>population</th>\n",
              "      <th>pop_cat</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>역삼1동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.103659</td>\n",
              "      <td>0.211382</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0.058065</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.060976</td>\n",
              "      <td>0.167480</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.252174</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.701334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>서교동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017073</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.078261</td>\n",
              "      <td>0.564476</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.443535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>여의동</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.414634</td>\n",
              "      <td>0.154472</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.238710</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.109756</td>\n",
              "      <td>0.092683</td>\n",
              "      <td>0.212</td>\n",
              "      <td>0.234783</td>\n",
              "      <td>0.896263</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.372292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>종로1.2.3.4가동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.378049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.270968</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.081707</td>\n",
              "      <td>0.008130</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.095652</td>\n",
              "      <td>0.670800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.344148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>서초3동</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231707</td>\n",
              "      <td>0.284553</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.109677</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081707</td>\n",
              "      <td>0.089431</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.598984</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.276695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>돈암2동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073171</td>\n",
              "      <td>0.390244</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.019355</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.120325</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.069565</td>\n",
              "      <td>0.047493</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.136913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>묵1동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030488</td>\n",
              "      <td>0.203252</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051220</td>\n",
              "      <td>0.087805</td>\n",
              "      <td>0.172</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.130530</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.150274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>거여2동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081301</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>0.077419</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.019512</td>\n",
              "      <td>0.056911</td>\n",
              "      <td>0.284</td>\n",
              "      <td>0.121739</td>\n",
              "      <td>0.070061</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.194008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>가리봉동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.283871</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.233333</td>\n",
              "      <td>0.293902</td>\n",
              "      <td>0.034146</td>\n",
              "      <td>0.392</td>\n",
              "      <td>0.234783</td>\n",
              "      <td>0.062857</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.197634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>신정6동</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.310976</td>\n",
              "      <td>0.065041</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038710</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.106098</td>\n",
              "      <td>0.123577</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.060870</td>\n",
              "      <td>0.086493</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.217953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>424 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            dong  highway      ffnc  ...  population  pop_cat      diff\n",
              "278         역삼1동     0.00  0.129032  ...    1.000000      5.0  0.701334\n",
              "187          서교동     0.00  0.000000  ...    0.564476      5.0  0.443535\n",
              "277          여의동     1.00  0.870968  ...    0.896263      5.0  0.372292\n",
              "353  종로1.2.3.4가동     0.00  0.290323  ...    0.670800      5.0  0.344148\n",
              "193         서초3동     0.25  0.225806  ...    0.598984      5.0  0.276695\n",
              "..           ...      ...       ...  ...         ...      ...       ...\n",
              "87          돈암2동     0.00  0.032258  ...    0.047493      1.0 -0.136913\n",
              "117          묵1동     0.00  0.129032  ...    0.130530      2.0 -0.150274\n",
              "19          거여2동     0.00  0.064516  ...    0.070061      1.0 -0.194008\n",
              "3           가리봉동     0.00  0.032258  ...    0.062857      1.0 -0.197634\n",
              "259         신정6동     0.00  0.064516  ...    0.086493      1.0 -0.217953\n",
              "\n",
              "[424 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES8qrrl8vuRq"
      },
      "source": [
        "df2_sort.to_excel('sort_9218df.xlsx')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKbaAHtU8MD2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsnhn5m78MN8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}